{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exit Code:\n",
    "    0: Error opening file\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from parse import *\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_dict']\n",
      "     A\n",
      "     B\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define formatted display function\n",
    "Used to replace regular print function\n",
    "\"\"\"\n",
    "# Get name of an object\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "# Display with format\n",
    "def display(items, func=None):\n",
    "    print(namestr(items, globals()))\n",
    "    for item in items:\n",
    "        if func:\n",
    "            item = func(item)\n",
    "        print(\"     {0}\".format(item))\n",
    "\n",
    "# Test display\n",
    "test_dict = {\"A\": [1, 2, 3], \"B\": [4, 5, 6]}\n",
    "display(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base on each folder (ngram-1, ngram-2, ngram-3).\n",
    "# Create DataFrame: \n",
    "#    art_id; word_ngram_1; freq_ngram_1; word1_ngram_2; word2_ngram_2; freq_ngram_2; \n",
    "#    word1_ngram_3; word2_ngram_3; word3_ngram_3; freq_ngram_3; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define function to filter out directories ngram-1, ngram-2, n-gram3\n",
    "\"\"\"\n",
    "def valid_direct(direct_name):\n",
    "    assert isinstance(direct_name, str)\n",
    "    \n",
    "    # Eliminate the \"../\" in the front if there is one\n",
    "    if direct_name.startswith(\"../\"):\n",
    "        direct_name = direct_name[3:]\n",
    "    \n",
    "    # Exculde if name starts with \".\"\n",
    "    if direct_name.startswith(\".\"):\n",
    "        return False\n",
    "    \n",
    "    # Test if name starts with ngram\n",
    "    if direct_name.startswith(\"ngram\"):\n",
    "        return True\n",
    "    \n",
    "    # Otherwise\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ngram1', 'ngram2', 'ngram3']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get filtering results\n",
    "\"\"\"\n",
    "datapath = \"../\"\n",
    "directories = sorted([direct for direct in os.listdir(datapath) if valid_direct(direct)])\n",
    "print(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function filtering files by filenames.\n",
    "-- Only accepts files starts with \"journal-article\"\n",
    "\"\"\"\n",
    "def filter_by_filename(files_list):\n",
    "    filtered_list = []\n",
    "    for filename in files_list:\n",
    "        # Check if the filename starts with \"journal-article\"\n",
    "        assert isinstance(filename, str)\n",
    "        # Check the first 20 characters of the file name\n",
    "        if filename.startswith(\"journal-article\", 0, 20):\n",
    "            filtered_list.append(filename)\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define function getting article ID from a filename by parsing pattern\n",
    "\"\"\"\n",
    "def parse_id(filename, pattern):\n",
    "    return parse(pattern, filename)[\"art_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define function extract article IDs from filenames\n",
    "-- parsing tricks learned from \"https://pypi.org/project/parse/\"\n",
    "\"\"\"\n",
    "def extract_id(files_list, direct):\n",
    "    # direct -> \"ngram1\" || \"ngram2\" || \"ngram3\"\n",
    "    \n",
    "    art_id_lst = []\n",
    "    \n",
    "    # Define Pattern\n",
    "    pattern = \"journal-article-10.2307_{art_id}-\" + direct + \".txt\"\n",
    "    \n",
    "    # Match filenames with pattern\n",
    "    for filename in files_list:\n",
    "        art_id_lst.append(parse_id(filename, pattern))\n",
    "    \n",
    "    return art_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define function extract all article IDs under a directory\n",
    "\"\"\"\n",
    "def get_id_lst(direct):\n",
    "    directpath = join(datapath, direct)\n",
    "    \n",
    "    # Get files under a directory\n",
    "    files_list = [file for file in listdir(directpath) if isfile(join(directpath, file))]\n",
    "    \n",
    "    # Filter files by filenames\n",
    "    files_list = filter_by_filename(files_list)\n",
    "    \n",
    "    # Parsing the filenames to extract IDs\n",
    "    art_id_lst = extract_id(files_list, direct)\n",
    "    \n",
    "    return art_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['art_id_lsts']\n",
      "     ['145203', '145208', '145211', '145213', '145215', '145216', '145218', '145221', '145224', '145226', '145227', '145230', '145231', '145233', '145234', '145235', '145242', '145286', '145288', '145292']\n",
      "     ['145203', '145208', '145211', '145213', '145215', '145216', '145218', '145221', '145224', '145226', '145227', '145230', '145231', '145233', '145234', '145235', '145242', '145286', '145288', '145292']\n",
      "     ['145203', '145208', '145211', '145213', '145215', '145216', '145218', '145221', '145224', '145226', '145227', '145230', '145231', '145233', '145234', '145235', '145242', '145286', '145288', '145292']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get ID lists for each ngram data set\n",
    "\"\"\"\n",
    "art_id_lsts = [get_id_lst(direct) for direct in directories]\n",
    "display(art_id_lsts, sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check if all article IDs co-exist in three directorys\n",
    "\"\"\"\n",
    "# Define a function comparing list\n",
    "def compare_lst(lst1, lst2):\n",
    "    return Counter(lst1) == Counter(lst2)\n",
    "\n",
    "# Check if all ngram data sets share same set of article IDs\n",
    "check_co_exist = art_id_lsts and all(compare_lst(art_id_lsts[0], art_id_lst) for art_id_lst in art_id_lsts)\n",
    "\n",
    "# Check result\n",
    "print(check_co_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCollect ngram cleaning results by our indivisually analyzed results\\nRead data from \"Result_journal-.....txt\"\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Collect ngram cleaning results by our indivisually analyzed results\n",
    "Read data from \"Result_journal-.....txt\"\n",
    "\"\"\"\n",
    "# ngram = [ngram_1, ngram_2, ngram_3]\n",
    "# ngram_1 = [words_ngram_1, freq_ngram_1]\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filter out Result files\n",
    "-- Only save those starts with \"Result_journal-article\"\n",
    "\"\"\"\n",
    "def filter_for_results(files_list):\n",
    "    filtered_list = []\n",
    "    for filename in files_list:\n",
    "        \n",
    "        # Check if the filename starts with \"Result_journal-article\"\n",
    "        assert isinstance(filename, str)\n",
    "        \n",
    "        # Check the first 20 characters of the file name\n",
    "        if filename.startswith(\"Result_journal-article\"):\n",
    "            filtered_list.append(filename)\n",
    "            \n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define a function to collect data from ngram results\n",
    "-- Output [words_ngram_X, freq_ngram_X]\n",
    "\"\"\"\n",
    "def collect_data(direct):\n",
    "    directpath = join(datapath, direct)\n",
    "    \n",
    "    # Get files under a directory\n",
    "    files_list = [file for file in listdir(directpath) if isfile(join(directpath, file))]\n",
    "    \n",
    "    # Filter files by filenames\n",
    "    filtered_list = filter_for_results(files_list)\n",
    "    \n",
    "    # Sum of freq lists\n",
    "    # freq_lists -> {ID1: freq_list1, ID2: freq_list2}\n",
    "    freq_lists = {}\n",
    "    \n",
    "    # Iterate through files\n",
    "    for filename in filtered_list:\n",
    "        # Open file\n",
    "        try:\n",
    "            file_open = open(join(directpath, filename), mode=\"r\")\n",
    "        except Exception as e:\n",
    "            print(\"Error opening file {0}\".format(filename))\n",
    "            print(\"Error message: <{0}>\".format(e))\n",
    "            exit(0)\n",
    "        \n",
    "        # Initiate freq_list -> [[words0, freq0], [words1, freq1]]\n",
    "        freq_list = []\n",
    "        \n",
    "        # Read by line\n",
    "        for line in file_open:\n",
    "            # line -> \"word1 word2 word3 5\"\n",
    "            assert isinstance(line, str)\n",
    "            \n",
    "            # pair -> \"[\"word1\", \"word2\", \"word3\", \"5\"]\n",
    "            pair = line.strip().split()\n",
    "            assert len(pair) >= 2\n",
    "\n",
    "            # Separate word/freq\n",
    "            words, freq = pair[:-1], pair[-1]\n",
    "            assert freq.isdigit()\n",
    "\n",
    "            # Append new pair to freq_list\n",
    "            freq_list.append([words, freq])\n",
    "        \n",
    "        # Close reading file\n",
    "        file_open.close()\n",
    "        \n",
    "        # Get article/file ID\n",
    "        pattern = \"Result_journal-article-10.2307_{art_id}-\" + direct + \".txt\"\n",
    "        art_id = parse_id(filename, pattern)\n",
    "        \n",
    "        # Append to overall list\n",
    "        freq_lists.update({art_id : freq_list})\n",
    "            \n",
    "    return freq_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTest freq_lists\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Collect data from ngrams\n",
    "\"\"\"\n",
    "# Sequence is very important here since it matters the sequence we save data in \"ngrams\"\n",
    "assert directories == sorted(directories)\n",
    "\n",
    "ngrams = []\n",
    "for direct in directories:\n",
    "    # Collect data\n",
    "    data = collect_data(direct)\n",
    "    assert len(data) > 0\n",
    "\n",
    "    ngrams.append(data)\n",
    "\n",
    "\"\"\"\n",
    "Test freq_lists\n",
    "\"\"\"\n",
    "# index = 1\n",
    "# for key in ngrams[index]:\n",
    "#     print(key)\n",
    "#     display(ngrams[index][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreate DataFrames:\\n    art_id; word_ngram_1; freq_ngram_1; \\n    art_id; word1_ngram_2; word2_ngram_2; freq_ngram_2; \\n    art_id; word1_ngram_3; word2_ngram_3; word3_ngram_3; freq_ngram_3; \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create DataFrames:\n",
    "    art_id; word_ngram_1; freq_ngram_1; \n",
    "    art_id; word1_ngram_2; word2_ngram_2; freq_ngram_2; \n",
    "    art_id; word1_ngram_3; word2_ngram_3; word3_ngram_3; freq_ngram_3; \n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define function to create DataFrame for N-Gram-X\n",
    "\"\"\"\n",
    "def create_DataFrame(columns):\n",
    "    # An API variable indicating which ngram should be selected from ngrams\n",
    "    # The calculation is because we eliminate the art_id and freq_ngram_x and then -1, totally 3\n",
    "    ngram_num = len(columns) - 3\n",
    "\n",
    "    \"\"\"\n",
    "    DATA\n",
    "    \"\"\"\n",
    "    # Data\n",
    "    data = []\n",
    "\n",
    "    # Get article ID list\n",
    "    # Review that we get art_id_lst in this way only if we are sure that ngram1/2/3 share same articles (IDs)\n",
    "    assert check_co_exist\n",
    "    art_id_lst = art_id_lsts[0]\n",
    "\n",
    "    # Generate data by lines\n",
    "    for art_id in art_id_lst:\n",
    "\n",
    "        # Make sure the sequence is correct that matches the dataframe column titles\n",
    "        # ngram -> {ID1: freq_list1, ID2: freq_list2}\n",
    "        # freq_list -> [[words0, freq0], [words1, freq1]]\n",
    "        ngram = ngrams[ngram_num]\n",
    "        assert art_id in ngram.keys()\n",
    "\n",
    "        # Get freq_list\n",
    "        freq_list = ngram[art_id]\n",
    "        assert len(freq_list) > 0\n",
    "        assert len(freq_list[0]) >= 2\n",
    "\n",
    "        # Treat unigram and others seperately\n",
    "        for pair in freq_list:\n",
    "            # dataline -> [art_id, word_ngram_1, freq_ngram_1] as section title comment issues\n",
    "            dataline = []\n",
    "\n",
    "            # Add art_id to dataline\n",
    "            dataline.append(art_id)\n",
    "\n",
    "            # pair -> [[words], freq]\n",
    "            assert len(pair) == 2\n",
    "\n",
    "            # Separate word/freq\n",
    "            words, freq = pair[0], pair[1]\n",
    "            assert freq.isdigit()\n",
    "            for word in words:\n",
    "                dataline.append(word)\n",
    "            dataline.append(freq)\n",
    "            \n",
    "            # Now the dataline should be complete\n",
    "            data.append(dataline)\n",
    "\n",
    "    \"\"\"\n",
    "    Columns\n",
    "    \"\"\"\n",
    "    columns = columns\n",
    "\n",
    "    \"\"\"\n",
    "    Index\n",
    "    \"\"\"\n",
    "    index = list(range(len(data)))\n",
    "\n",
    "    \"\"\"\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    dataframe = pd.DataFrame(data, columns=columns, index=index)\n",
    "\n",
    "    \"\"\"\n",
    "    Test DataFrame\n",
    "    \"\"\"\n",
    "    print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All Columns features for N-Gram [1-3]\n",
    "\"\"\"\n",
    "ngram_columns = [\n",
    "    [\"art_id\", \"word_ngram_1\", \"freq_ngram_1\"],\n",
    "    [\"art_id\", \"word1_ngram_2\", \"word2_ngram_2\", \"freq_ngram_2\"],\n",
    "    [\"art_id\", \"word1_ngram_3\", \"word2_ngram_3\", \"word3_ngram_3\", \"freq_ngram_3\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   art_id word_ngram_1 freq_ngram_1\n",
      "0  145292    licensing           58\n",
      "1  145292      written           40\n",
      "2  145292  examination           32\n",
      "3  145292         test           32\n",
      "4  145292      workers           27\n",
      "   art_id word1_ngram_2 word2_ngram_2 freq_ngram_2\n",
      "0  145292       written          test           17\n",
      "1  145292  occupational     licensing           12\n",
      "2  145292             i             i           11\n",
      "3  145292       written   examination           11\n",
      "4  145292     licensing  examinations           10\n",
      "   art_id word1_ngram_3 word2_ngram_3 word3_ngram_3 freq_ngram_3\n",
      "0  145292             i             i             i            9\n",
      "1  145292       journal         human     resources            6\n",
      "2  145292       written     licensing  examinations            4\n",
      "3  145292       attempt        obtain       license            2\n",
      "4  145292    attributes     important       passing            2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DataFrame Creation for N-Gram [1-3]\n",
    "\"\"\"\n",
    "dataframe1 = create_DataFrame(ngram_columns[0])\n",
    "dataframe2 = create_DataFrame(ngram_columns[1])\n",
    "dataframe3 = create_DataFrame(ngram_columns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
