{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error Code:\n",
    "    0: Error opening file\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "# Clarify the mission N number for this .ipynb\n",
    "N_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_dict']\n",
      "    A\n",
      "    B\n"
     ]
    }
   ],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "def display(items):\n",
    "    print(namestr(items, globals()))\n",
    "    for item in items:\n",
    "        print(\"    \" + item)\n",
    "\n",
    "# Test display\n",
    "test_dict = {\"A\": [1, 2, 3], \"B\": [4, 5, 6]}\n",
    "display(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 files detected under current directory. \n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = \"./\"\n",
    "zip_file_name = \"journals\"\n",
    "zip_file = zipfile.ZipFile(mypath + zip_file_name + \".zip\")\n",
    "file_name_list = zip_file.namelist()\n",
    "# Should return 4 folders if testing on ASG Zip\n",
    "print(\"{0} files detected under current directory. \".format(len(file_name_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 files remained after filename filtering. \n"
     ]
    }
   ],
   "source": [
    "def filter_by_filename(files_list):\n",
    "    \"\"\"Function filtering files by filenames.\n",
    "    Only accepts files starts with \"journal-article\"\n",
    "    \"\"\"\n",
    "    filtered_list = []\n",
    "    mask_match = zip_file_name + \"/ngram\" + str(N_number) + \"/journal-article\"\n",
    "    for filename in files_list:\n",
    "        # Check if the filename starts with \"journal-article\"\n",
    "        assert isinstance(filename, str)\n",
    "        # Check the first 20 characters of the file name\n",
    "        if filename.startswith(mask_match, 0, len(mask_match)):\n",
    "            filtered_list.append(filename)\n",
    "    return filtered_list\n",
    "\n",
    "# Run \"filter_by_filename\" for current directory\n",
    "filtered_list = filter_by_filename(file_name_list)\n",
    "print(\"{0} files remained after filename filtering. \".format(len(filtered_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions checking word attributes (single-letter, starts/ends with numebr)\n",
    "def is_single_letter(word):\n",
    "    assert isinstance(word, str)\n",
    "    return len(word) <= 1\n",
    "\n",
    "def starts_with_number(word):\n",
    "    assert isinstance(word, str)\n",
    "    try:\n",
    "        return word[0].isdigit()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def ends_with_number(word):\n",
    "    assert isinstance(word, str)\n",
    "    try:\n",
    "        return word[len(word) - 1].isdigit()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Summary of check functions\n",
    "check_funcs = [\n",
    "    is_single_letter, \n",
    "    starts_with_number, \n",
    "    ends_with_number,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_0 = filtered_list[0]\n",
    "try:\n",
    "    journal_0 = zip_file.open(file_0, mode=\"r\")\n",
    "except IOError:\n",
    "    print(\"Error opening file {0}\".format(file_0))\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq_dict']\n",
      "    pp\n",
      "    paper\n",
      "    cloth\n",
      "    price\n",
      "    listed\n",
      "    institute\n",
      "    research\n",
      "    ed\n",
      "    new\n",
      "    policy\n",
      "    washington\n",
      "    ma\n",
      "    public\n",
      "    york\n",
      "    american\n",
      "    enterprise\n",
      "    co\n",
      "    social\n",
      "    employment\n",
      "    press\n",
      "    publications\n",
      "    publishing\n",
      "    ca\n",
      "    cambridge\n",
      "    danish\n",
      "    housing\n",
      "    labor\n",
      "    university\n",
      "    douglas\n",
      "    economic\n",
      "    economics\n",
      "    health\n",
      "    human\n",
      "    london\n",
      "    problems\n",
      "    report\n",
      "    united\n",
      "    welfare\n",
      "    work\n",
      "    academic\n",
      "    adams\n",
      "    allan\n",
      "    allowance\n",
      "    approach\n",
      "    assistance\n",
      "    ballinger\n",
      "    care\n",
      "    commission\n",
      "    committee\n",
      "    community\n",
      "    consequences\n",
      "    copenhagen\n",
      "    corporation\n",
      "    current\n",
      "    effects\n",
      "    english\n",
      "    experiment\n",
      "    final\n",
      "    handbook\n",
      "    immigration\n",
      "    inc\n",
      "    international\n",
      "    issues\n",
      "    jerry\n",
      "    journal\n",
      "    kalamazoo\n",
      "    mark\n",
      "    market\n",
      "    markets\n",
      "    massachusetts\n",
      "    mi\n",
      "    monica\n",
      "    national\n",
      "    neal\n",
      "    neale\n",
      "    participation\n",
      "    phillip\n",
      "    politics\n",
      "    prodist\n",
      "    program\n",
      "    progress\n",
      "    rand\n",
      "    received\n",
      "    reform\n",
      "    resources\n",
      "    robert\n",
      "    santa\n",
      "    services\n",
      "    states\n",
      "    summary\n",
      "    supply\n",
      "    survey\n",
      "    sydney\n",
      "    systems\n",
      "    theory\n",
      "    upjohn\n",
      "    watson\n",
      "    women\n",
      "    addison\n",
      "    albany\n",
      "    alcohol\n",
      "    alice\n",
      "    alienation\n",
      "    allen\n",
      "    amherst\n",
      "    among\n",
      "    analysis\n",
      "    andersen\n",
      "    angela\n",
      "    ann\n",
      "    application\n",
      "    applying\n",
      "    arbejdstidspolitik\n",
      "    aronowitz\n",
      "    assessment\n",
      "    association\n",
      "    attitudes\n",
      "    australian\n",
      "    authenticity\n",
      "    bangladesh\n",
      "    bank\n",
      "    barnett\n",
      "    barry\n",
      "    baxter\n",
      "    been\n",
      "    bellante\n",
      "    berent\n",
      "    beverly\n",
      "    biklen\n",
      "    bjarne\n",
      "    black\n",
      "    blacks\n",
      "    bob\n",
      "    book\n",
      "    books\n",
      "    borus\n",
      "    bowey\n",
      "    brian\n",
      "    brookings\n",
      "    brookline\n",
      "    budget\n",
      "    bureaucratic\n",
      "    business\n",
      "    cagan\n",
      "    cambron\n",
      "    capital\n",
      "    carter\n",
      "    case\n",
      "    change\n",
      "    changing\n",
      "    china\n",
      "    chiswick\n",
      "    choice\n",
      "    christffersen\n",
      "    cincinnati\n",
      "    circle\n",
      "    civil\n",
      "    claims\n",
      "    clarendon\n",
      "    clearinghouse\n",
      "    cliffs\n",
      "    closed\n",
      "    communities\n",
      "    comparative\n",
      "    comparison\n",
      "    compensation\n",
      "    computer\n",
      "    concepts\n",
      "    conference\n",
      "    contributions\n",
      "    control\n",
      "    critique\n",
      "    ct\n",
      "    cwep\n",
      "    daniel\n",
      "    daryl\n",
      "    david\n",
      "    decisions\n",
      "    decline\n",
      "    department\n",
      "    differences\n",
      "    directions\n",
      "    disability\n",
      "    don\n",
      "    economy\n",
      "    eds\n",
      "    education\n",
      "    edward\n",
      "    el\n",
      "    elkin\n",
      "    englewood\n",
      "    enrollment\n",
      "    environment\n",
      "    ernie\n",
      "    eugene\n",
      "    europe\n",
      "    extension\n",
      "    family\n",
      "    fanny\n",
      "    federation\n",
      "    fellner\n",
      "    fertility\n",
      "    finance\n",
      "    focusing\n",
      "    frontline\n",
      "    gale\n",
      "    game\n",
      "    gary\n",
      "    general\n",
      "    geoff\n",
      "    gold\n",
      "    gosnold\n",
      "    grace\n",
      "    grant\n",
      "    group\n",
      "    growth\n",
      "    hall\n",
      "    hans\n",
      "    happening\n",
      "    hardship\n",
      "    has\n",
      "    haven\n",
      "    heath\n",
      "    helen\n",
      "    hellier\n",
      "    help\n",
      "    henrik\n",
      "    hernandez\n",
      "    high\n",
      "    hill\n",
      "    hills\n",
      "    hispanics\n",
      "    history\n",
      "    hjorth\n",
      "    holdninger\n",
      "    hours\n",
      "    hud\n",
      "    hunt\n",
      "    immigrants\n",
      "    incentive\n",
      "    inequality\n",
      "    institution\n",
      "    institutions\n",
      "    integration\n",
      "    interview\n",
      "    interviewunders0gelser\n",
      "    introduction\n",
      "    iola\n",
      "    jack\n",
      "    jackson\n",
      "    james\n",
      "    jennifer\n",
      "    job\n",
      "    johnson\n",
      "    jr\n",
      "    justice\n",
      "    kenneth\n",
      "    kevin\n",
      "    kingdom\n",
      "    lance\n",
      "    lang\n",
      "    lately\n",
      "    lave\n",
      "    lawson\n",
      "    lester\n",
      "    lexington\n",
      "    limits\n",
      "    macroeconomic\n",
      "    managing\n",
      "    mashaw\n",
      "    maurice\n",
      "    max\n",
      "    mccabe\n",
      "    mcgraw\n",
      "    medicine\n",
      "    mental\n",
      "    methuen\n",
      "    metropolitan\n",
      "    meyer\n",
      "    michael\n",
      "    michigan\n",
      "    milestones\n",
      "    mills\n",
      "    mit\n",
      "    mitchell\n",
      "    mogens\n",
      "    monetary\n",
      "    moore\n",
      "    morkeberg\n",
      "    nancy\n",
      "    neels\n",
      "    nelda\n",
      "    netherlands\n",
      "    nicholls\n",
      "    nj\n",
      "    ny\n",
      "    nygaard\n",
      "    odden\n",
      "    oh\n",
      "    om\n",
      "    open\n",
      "    organization\n",
      "    organized\n",
      "    organizing\n",
      "    osgood\n",
      "    osmani\n",
      "    output\n",
      "    oxford\n",
      "    past\n",
      "    patterns\n",
      "    payment\n",
      "    peed\n",
      "    people\n",
      "    perlman\n",
      "    perspectives\n",
      "    peter\n",
      "    planning\n",
      "    police\n",
      "    policies\n",
      "    poor\n",
      "    potential\n",
      "    practice\n",
      "    praeger\n",
      "    prentice\n",
      "    prevention\n",
      "    problemer\n",
      "    proceedings\n",
      "    prochaska\n",
      "    productivity\n",
      "    programme\n",
      "    publication\n",
      "    punch\n",
      "    quality\n",
      "    quantitative\n",
      "    question\n",
      "    questionnaires\n",
      "    rahman\n",
      "    randyl\n",
      "    reading\n",
      "    recent\n",
      "    reforming\n",
      "    reforms\n",
      "    regional\n",
      "    regulation\n",
      "    rehr\n",
      "    republic\n",
      "    retirement\n",
      "    richard\n",
      "    rights\n",
      "    risk\n",
      "    rydell\n",
      "    sage\n",
      "    savery\n",
      "    schenkman\n",
      "    schirmer\n",
      "    school\n",
      "    sector\n",
      "    security\n",
      "    senior\n",
      "    settlers\n",
      "    siddiqur\n",
      "    skrovan\n",
      "    some\n",
      "    south\n",
      "    sp0rgeskemaer\n",
      "    sp0rgsmalformulering\n",
      "    standard\n",
      "    stanley\n",
      "    state\n",
      "    statistical\n",
      "    strategic\n",
      "    strategies\n",
      "    study\n",
      "    surveys\n",
      "    system\n",
      "    taggart\n",
      "    tavistock\n",
      "    technology\n",
      "    thorpe\n",
      "    through\n",
      "    til\n",
      "    toch\n",
      "    tomorrow\n",
      "    toro\n",
      "    trade\n",
      "    two\n",
      "    underemployment\n",
      "    unemployment\n",
      "    unions\n",
      "    unwin\n",
      "    usa\n",
      "    ved\n",
      "    versus\n",
      "    voorburg\n",
      "    wendt\n",
      "    wesley\n",
      "    western\n",
      "    what\n",
      "    william\n",
      "    winchester\n",
      "    withorn\n",
      "    wording\n",
      "    worker\n",
      "    workers\n",
      "    working\n",
      "    worklife\n",
      "    world\n",
      "    would\n",
      "    xviii\n",
      "    yale\n"
     ]
    }
   ],
   "source": [
    "# Track the meaningful dictonaries\n",
    "freq_dict = {}\n",
    "\n",
    "# Read file line by line\n",
    "for line in journal_0:\n",
    "    line = line.decode(\"ascii\") \n",
    "    assert isinstance(line, str)\n",
    "    pair = line.strip().split()\n",
    "    \n",
    "    # Separate word/freq\n",
    "    word, freq = pair\n",
    "    assert isinstance(word, str)\n",
    "    \n",
    "    # Filter by word's attribute\n",
    "    check_results = [check_func(word) for check_func in check_funcs]\n",
    "    if any(check_results):\n",
    "        continue\n",
    "    freq_dict.update({word: freq})\n",
    "\n",
    "journal_0.close()\n",
    "display(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pp</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloth</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>price</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>listed</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word freq\n",
       "0      pp   39\n",
       "1   paper   27\n",
       "2   cloth   17\n",
       "3   price   17\n",
       "4  listed   16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "# Data\n",
    "data = []\n",
    "for word in freq_dict:\n",
    "    freq = freq_dict[word]\n",
    "    data.append([word, freq])\n",
    "\n",
    "# Columns\n",
    "columns = [\"word\", \"freq\"]\n",
    "\n",
    "# Index\n",
    "index = list(range(len(freq_dict)))\n",
    "\n",
    "# DataFrame\n",
    "dataframe = pd.DataFrame(data, columns=columns, index=index)\n",
    "\n",
    "# Print Test\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results_1/journal-article-10.2307_145213-ngram1.txt\n",
      "     word freq\n",
      "0      pp   39\n",
      "1   paper   27\n",
      "2   cloth   17\n",
      "3   price   17\n",
      "4  listed   16\n",
      "Results_1/journal-article-10.2307_145224-ngram1.txt\n",
      "      word freq\n",
      "0   search  112\n",
      "1      job   55\n",
      "2      ojs   51\n",
      "3     wage   43\n",
      "4  workers   35\n",
      "Results_1/journal-article-10.2307_145221-ngram1.txt\n",
      "           word freq\n",
      "0      earnings   63\n",
      "1   achievement   37\n",
      "2    motivation   35\n",
      "3    background   34\n",
      "4  intelligence   33\n",
      "Results_1/journal-article-10.2307_145216-ngram1.txt\n",
      "       word freq\n",
      "0  teachers  160\n",
      "1    school   85\n",
      "2   teacher   72\n",
      "3   schools   53\n",
      "4  transfer   42\n",
      "Results_1/journal-article-10.2307_145226-ngram1.txt\n",
      "       word freq\n",
      "0  earnings   41\n",
      "1   college   20\n",
      "2  security   18\n",
      "3    social   18\n",
      "4    school   16\n",
      "Results_1/journal-article-10.2307_145211-ngram1.txt\n",
      "       word freq\n",
      "0        ui   64\n",
      "1    search   48\n",
      "2       job   28\n",
      "3  benefits   25\n",
      "4      data   15\n",
      "Results_1/journal-article-10.2307_145208-ngram1.txt\n",
      "         word freq\n",
      "0        quit   86\n",
      "1         pay   71\n",
      "2  government   65\n",
      "3        size   64\n",
      "4        firm   54\n",
      "Results_1/journal-article-10.2307_145203-ngram1.txt\n",
      "         word freq\n",
      "0   wisconsin   10\n",
      "1     journal    9\n",
      "2    research    9\n",
      "3       human    8\n",
      "4  university    7\n",
      "Results_1/journal-article-10.2307_145218-ngram1.txt\n",
      "        word freq\n",
      "0    poverty  130\n",
      "1   earnings  114\n",
      "2  transfers   98\n",
      "3     growth   56\n",
      "4        aed   50\n",
      "Results_1/journal-article-10.2307_145215-ngram1.txt\n",
      "         word freq\n",
      "0   wisconsin   20\n",
      "1   economics   16\n",
      "2    research   13\n",
      "3     poverty    7\n",
      "4  university    7\n"
     ]
    }
   ],
   "source": [
    "# Run filtering for each file\n",
    "for file in filtered_list:\n",
    "    # Open file\n",
    "    try:\n",
    "        file_open = zip_file.open(file, mode=\"r\")\n",
    "    except IOError:\n",
    "        print(\"Error opening file {0}\".format(file))\n",
    "        exit(0)\n",
    "    \n",
    "    # Create output file\n",
    "    output_name = \"Results_1\" + file[len(zip_file_name) + len(\"/ngram\" + str(N_number)):]\n",
    "    \n",
    "    print(output_name)\n",
    "    \n",
    "    # Note: Output file encoding set to UTF-8\n",
    "    output_file = open(output_name, mode=\"w+\", encoding=\"utf-8\")\n",
    "    \n",
    "    # Track for max length word\n",
    "    # Used for formatting output data\n",
    "    max_length = float(\"-inf\")\n",
    "        \n",
    "    # Initiate freq_dict -> {word: freq}\n",
    "    freq_dict = {}\n",
    "    \n",
    "    # Read by line\n",
    "    for line in file_open:\n",
    "        # Line decode using UTF-8\n",
    "        line = line.decode(\"utf-8\")\n",
    "        assert isinstance(line, str)\n",
    "        pair = line.strip().split()\n",
    "    \n",
    "        # Separate word/freq\n",
    "        word, freq = pair\n",
    "        assert isinstance(word, str)\n",
    "        \n",
    "        # Filter by word's attribute\n",
    "        check_results = [check_func(word) for check_func in check_funcs]\n",
    "        if any(check_results):\n",
    "            continue\n",
    "            \n",
    "        # Update max_length\n",
    "        if len(word) > max_length:\n",
    "            max_length = len(word)\n",
    "        freq_dict.update({word: freq})\n",
    "    \n",
    "    # Close reading file\n",
    "    file_open.close()\n",
    "    \n",
    "    # Create Dataframe\n",
    "    # Data\n",
    "    data = []\n",
    "    for word in freq_dict:\n",
    "        freq = freq_dict[word]\n",
    "        data.append([word, freq])\n",
    "    \n",
    "    # Columns\n",
    "    columns = [\"word\", \"freq\"]\n",
    "    \n",
    "    # Index\n",
    "    index = list(range(len(freq_dict)))\n",
    "    \n",
    "    # DataFrame\n",
    "    dataframe = pd.DataFrame(data, columns=columns, index=index)\n",
    "    \n",
    "    # Write to output file\n",
    "    for word in freq_dict:\n",
    "        freq = freq_dict[word]\n",
    "        output_file.write(word.ljust(max_length + 5))\n",
    "        output_file.write(freq + \"\\n\")\n",
    "    \n",
    "    output_file.close()\n",
    "    print(dataframe.head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
