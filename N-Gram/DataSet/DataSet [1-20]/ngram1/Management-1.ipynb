{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error Code:\n",
    "    0: Error opening file\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_dict']\n",
      "    A\n",
      "    B\n"
     ]
    }
   ],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "def display(items):\n",
    "    print(namestr(items, globals()))\n",
    "    for item in items:\n",
    "        print(\"    \" + item)\n",
    "\n",
    "# Test display\n",
    "test_dict = {\"A\": [1, 2, 3], \"B\": [4, 5, 6]}\n",
    "display(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 files detected under current directory. \n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = \"./\"\n",
    "files_list = [file for file in listdir(mypath) if isfile(join(mypath, file))]\n",
    "print(\"{0} files detected under current directory. \".format(len(files_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 files remained after filename filtering. \n"
     ]
    }
   ],
   "source": [
    "def filter_by_filename(files_list):\n",
    "    \"\"\"Function filtering files by filenames.\n",
    "    Only accepts files starts with \"journal-article\"\n",
    "    \"\"\"\n",
    "    filtered_list = []\n",
    "    for filename in files_list:\n",
    "        # Check if the filename starts with \"journal-article\"\n",
    "        assert isinstance(filename, str)\n",
    "        # Check the first 20 characters of the file name\n",
    "        if filename.startswith(\"journal-article\", 0, 20):\n",
    "            filtered_list.append(filename)\n",
    "    return filtered_list\n",
    "\n",
    "# Run \"filter_by_filename\" for current directory\n",
    "filtered_list = filter_by_filename(files_list)\n",
    "print(\"{0} files remained after filename filtering. \".format(len(filtered_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions checking word attributes (single-letter, starts/ends with numebr)\n",
    "def is_single_letter(word):\n",
    "    assert isinstance(word, str)\n",
    "    return len(word) <= 1\n",
    "\n",
    "def starts_with_number(word):\n",
    "    assert isinstance(word, str)\n",
    "    try:\n",
    "        return word[0].isdigit()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def ends_with_number(word):\n",
    "    assert isinstance(word, str)\n",
    "    try:\n",
    "        return word[len(word) - 1].isdigit()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Summary of check functions\n",
    "check_funcs = [\n",
    "    is_single_letter, \n",
    "    starts_with_number, \n",
    "    ends_with_number,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_0 = filtered_list[0]\n",
    "try:\n",
    "    journal_0 = open(file_0, mode=\"r\")\n",
    "except IOError:\n",
    "    print(\"Error opening file {0}\".format(file_0))\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq_dict']\n",
      "    licensing\n",
      "    written\n",
      "    examination\n",
      "    test\n",
      "    workers\n",
      "    applicants\n",
      "    practical\n",
      "    have\n",
      "    illinois\n",
      "    training\n",
      "    education\n",
      "    who\n",
      "    would\n",
      "    examinations\n",
      "    than\n",
      "    missouri\n",
      "    occupation\n",
      "    from\n",
      "    less\n",
      "    may\n",
      "    occupational\n",
      "    entry\n",
      "    any\n",
      "    more\n",
      "    applicant\n",
      "    journal\n",
      "    market\n",
      "    were\n",
      "    ability\n",
      "    cosmetology\n",
      "    likely\n",
      "    lower\n",
      "    percent\n",
      "    scores\n",
      "    those\n",
      "    trade\n",
      "    fail\n",
      "    has\n",
      "    new\n",
      "    only\n",
      "    passing\n",
      "    public\n",
      "    school\n",
      "    score\n",
      "    advantage\n",
      "    blacks\n",
      "    can\n",
      "    characteristics\n",
      "    entrants\n",
      "    excluded\n",
      "    must\n",
      "    performance\n",
      "    quality\n",
      "    requirements\n",
      "    resources\n",
      "    sample\n",
      "    shimberg\n",
      "    tests\n",
      "    university\n",
      "    attempt\n",
      "    attributes\n",
      "    both\n",
      "    costs\n",
      "    does\n",
      "    educated\n",
      "    effect\n",
      "    formal\n",
      "    human\n",
      "    important\n",
      "    measure\n",
      "    minimum\n",
      "    number\n",
      "    pp\n",
      "    queue\n",
      "    received\n",
      "    schools\n",
      "    table\n",
      "    washington\n",
      "    wpass\n",
      "    additional\n",
      "    all\n",
      "    also\n",
      "    appears\n",
      "    apprentices\n",
      "    apprenticeship\n",
      "    because\n",
      "    could\n",
      "    economics\n",
      "    effects\n",
      "    even\n",
      "    first\n",
      "    general\n",
      "    groups\n",
      "    however\n",
      "    information\n",
      "    licenses\n",
      "    likelihood\n",
      "    loss\n",
      "    potential\n",
      "    price\n",
      "    race\n",
      "    require\n",
      "    result\n",
      "    some\n",
      "    study\n",
      "    thus\n",
      "    two\n",
      "    variables\n",
      "    wage\n",
      "    we\n",
      "    age\n",
      "    apprentice\n",
      "    benefit\n",
      "    between\n",
      "    classroom\n",
      "    dependent\n",
      "    do\n",
      "    estimates\n",
      "    generally\n",
      "    high\n",
      "    labor\n",
      "    license\n",
      "    licensed\n",
      "    most\n",
      "    need\n",
      "    nonprofessional\n",
      "    often\n",
      "    others\n",
      "    output\n",
      "    paper\n",
      "    pass\n",
      "    pexamscore\n",
      "    possible\n",
      "    previous\n",
      "    productivity\n",
      "    regressions\n",
      "    rejected\n",
      "    requirement\n",
      "    restrictions\n",
      "    see\n",
      "    since\n",
      "    specific\n",
      "    supply\n",
      "    type\n",
      "    upon\n",
      "    variable\n",
      "    when\n",
      "    whether\n",
      "    absence\n",
      "    after\n",
      "    alternative\n",
      "    analysis\n",
      "    another\n",
      "    based\n",
      "    basic\n",
      "    basis\n",
      "    been\n",
      "    biases\n",
      "    board\n",
      "    candidates\n",
      "    cause\n",
      "    choose\n",
      "    coefficient\n",
      "    communications\n",
      "    competitive\n",
      "    constant\n",
      "    consumers\n",
      "    danger\n",
      "    dissertation\n",
      "    dorsey\n",
      "    each\n",
      "    earnings\n",
      "    failed\n",
      "    failure\n",
      "    fschool\n",
      "    further\n",
      "    graduates\n",
      "    group\n",
      "    had\n",
      "    higher\n",
      "    hours\n",
      "    improves\n",
      "    incentive\n",
      "    including\n",
      "    indicate\n",
      "    individuals\n",
      "    job\n",
      "    knowledge\n",
      "    logit\n",
      "    long\n",
      "    losses\n",
      "    made\n",
      "    making\n",
      "    multivariate\n",
      "    nearly\n",
      "    necessary\n",
      "    now\n",
      "    obtain\n",
      "    occupations\n",
      "    officials\n",
      "    one\n",
      "    other\n",
      "    practices\n",
      "    press\n",
      "    productive\n",
      "    rayack\n",
      "    receive\n",
      "    rejecting\n",
      "    restricted\n",
      "    results\n",
      "    run\n",
      "    samples\n",
      "    say\n",
      "    sector\n",
      "    set\n",
      "    significant\n",
      "    similar\n",
      "    systematically\n",
      "    testing\n",
      "    time\n",
      "    total\n",
      "    trades\n",
      "    trained\n",
      "    unrelated\n",
      "    used\n",
      "    wc\n",
      "    where\n",
      "    wl\n",
      "    year\n",
      "    years\n",
      "    able\n",
      "    admitted\n",
      "    affect\n",
      "    affected\n",
      "    against\n",
      "    already\n",
      "    american\n",
      "    appear\n",
      "    apprent\n",
      "    apprenticing\n",
      "    approved\n",
      "    april\n",
      "    argued\n",
      "    attractive\n",
      "    average\n",
      "    become\n",
      "    before\n",
      "    better\n",
      "    bias\n",
      "    biased\n",
      "    case\n",
      "    certain\n",
      "    chance\n",
      "    clear\n",
      "    coefficients\n",
      "    columns\n",
      "    comments\n",
      "    competency\n",
      "    competent\n",
      "    compiled\n",
      "    complete\n",
      "    conclusions\n",
      "    cosmetologists\n",
      "    cost\n",
      "    course\n",
      "    data\n",
      "    defined\n",
      "    difference\n",
      "    direct\n",
      "    discount\n",
      "    distributional\n",
      "    ec\n",
      "    economic\n",
      "    effective\n",
      "    eight\n",
      "    emphasis\n",
      "    equal\n",
      "    equals\n",
      "    equations\n",
      "    equilibrium\n",
      "    estimated\n",
      "    evaluated\n",
      "    evidence\n",
      "    exam\n",
      "    examina\n",
      "    example\n",
      "    exclude\n",
      "    experience\n",
      "    externalities\n",
      "    fall\n",
      "    feel\n",
      "    figure\n",
      "    flow\n",
      "    following\n",
      "    force\n",
      "    found\n",
      "    given\n",
      "    graded\n",
      "    grandfather\n",
      "    greater\n",
      "    green\n",
      "    here\n",
      "    identify\n",
      "    impact\n",
      "    included\n",
      "    index\n",
      "    influence\n",
      "    initial\n",
      "    intent\n",
      "    january\n",
      "    law\n",
      "    limited\n",
      "    manpower\n",
      "    many\n",
      "    meet\n",
      "    meeting\n",
      "    method\n",
      "    model\n",
      "    moore\n",
      "    much\n",
      "    national\n",
      "    october\n",
      "    official\n",
      "    ols\n",
      "    out\n",
      "    outside\n",
      "    over\n",
      "    particular\n",
      "    pc\n",
      "    period\n",
      "    ph\n",
      "    plus\n",
      "    point\n",
      "    points\n",
      "    potentially\n",
      "    ppfail\n",
      "    pq\n",
      "    practicing\n",
      "    presented\n",
      "    prices\n",
      "    princeton\n",
      "    private\n",
      "    probability\n",
      "    procedures\n",
      "    program\n",
      "    protect\n",
      "    purpose\n",
      "    question\n",
      "    quite\n",
      "    raises\n",
      "    rate\n",
      "    rates\n",
      "    reason\n",
      "    reduction\n",
      "    related\n",
      "    relative\n",
      "    rents\n",
      "    repeaters\n",
      "    report\n",
      "    restrict\n",
      "    restricting\n",
      "    return\n",
      "    rises\n",
      "    seem\n",
      "    sex\n",
      "    shepard\n",
      "    should\n",
      "    show\n",
      "    small\n",
      "    spaname\n",
      "    standards\n",
      "    state\n",
      "    states\n",
      "    statistics\n",
      "    still\n",
      "    stock\n",
      "    strong\n",
      "    stuart\n",
      "    students\n",
      "    success\n",
      "    tend\n",
      "    therefore\n",
      "    through\n",
      "    under\n",
      "    unregulated\n",
      "    unsafe\n",
      "    usually\n",
      "    vocational\n",
      "    vochs\n",
      "    wa\n",
      "    wages\n",
      "    wasted\n",
      "    welfare\n",
      "    well\n",
      "    which\n",
      "    whites\n",
      "    whose\n",
      "    willing\n",
      "    work\n",
      "    worker\n",
      "    wpfail\n",
      "    yet\n",
      "    york\n",
      "    abilities\n",
      "    about\n",
      "    absolute\n",
      "    absolutely\n",
      "    academic\n",
      "    accepted\n",
      "    accepts\n",
      "    accordingly\n",
      "    accurately\n",
      "    acquire\n",
      "    acquired\n",
      "    activity\n",
      "    actual\n",
      "    added\n",
      "    addition\n",
      "    administration\n",
      "    admission\n",
      "    affairs\n",
      "    ahead\n",
      "    algebra\n",
      "    alien\n",
      "    allow\n",
      "    allowing\n",
      "    alternatives\n",
      "    among\n",
      "    analogous\n",
      "    anatomy\n",
      "    antos\n",
      "    appearance\n",
      "    application\n",
      "    applied\n",
      "    appropriate\n",
      "    approx\n",
      "    approximately\n",
      "    argue\n",
      "    aspects\n",
      "    assembly\n",
      "    asserted\n",
      "    associated\n",
      "    association\n",
      "    assumption\n",
      "    assure\n",
      "    asymptotically\n",
      "    attempted\n",
      "    attempts\n",
      "    attract\n",
      "    attrition\n",
      "    automatic\n",
      "    automatically\n",
      "    available\n",
      "    avoided\n",
      "    barbara\n",
      "    barber\n",
      "    barbers\n",
      "    barrier\n",
      "    beautician\n",
      "    beauty\n",
      "    behavior\n",
      "    bell\n",
      "    below\n",
      "    benefited\n",
      "    benefits\n",
      "    benham\n",
      "    benjamin\n",
      "    best\n",
      "    beyond\n",
      "    biology\n",
      "    black\n",
      "    boards\n",
      "    burdensome\n",
      "    business\n",
      "    called\n",
      "    cannot\n",
      "    care\n",
      "    category\n",
      "    causes\n",
      "    cautiously\n",
      "    censing\n",
      "    center\n",
      "    chances\n",
      "    characteristic\n",
      "    choosing\n",
      "    chose\n",
      "    cites\n",
      "    citizenship\n",
      "    city\n",
      "    clause\n",
      "    clauses\n",
      "    college\n",
      "    column\n",
      "    comment\n",
      "    compara\n",
      "    comparable\n",
      "    competition\n",
      "    completed\n",
      "    comprise\n",
      "    compute\n",
      "    concentrated\n",
      "    concerned\n",
      "    confident\n",
      "    considered\n",
      "    considers\n",
      "    consists\n",
      "    consumer\n",
      "    contain\n",
      "    contend\n",
      "    content\n",
      "    continuous\n",
      "    contrast\n",
      "    control\n",
      "    cooperation\n",
      "    cope\n",
      "    correction\n",
      "    correlation\n",
      "    cosmetologist\n",
      "    costless\n",
      "    covered\n",
      "    creden\n",
      "    credentialism\n",
      "    criteria\n",
      "    cultural\n",
      "    currently\n",
      "    customers\n",
      "    daniel\n",
      "    david\n",
      "    defines\n",
      "    definition\n",
      "    definitions\n",
      "    definitive\n",
      "    demand\n",
      "    dent\n",
      "    dental\n",
      "    department\n",
      "    depend\n",
      "    depress\n",
      "    derivatives\n",
      "    derived\n",
      "    desired\n",
      "    details\n",
      "    determinants\n",
      "    determination\n",
      "    determine\n",
      "    determines\n",
      "    dichotomous\n",
      "    didates\n",
      "    differences\n",
      "    differentials\n",
      "    difficult\n",
      "    difficulty\n",
      "    directly\n",
      "    disadvantage\n",
      "    discriminate\n",
      "    discussion\n",
      "    drop\n",
      "    due\n",
      "    during\n",
      "    dynamics\n",
      "    earn\n",
      "    earned\n",
      "    easily\n",
      "    economists\n",
      "    edward\n",
      "    either\n",
      "    el\n",
      "    electricians\n",
      "    elimination\n",
      "    elton\n",
      "    emphasize\n",
      "    employer\n",
      "    employers\n",
      "    employment\n",
      "    encouraged\n",
      "    enforcement\n",
      "    english\n",
      "    enter\n",
      "    equation\n",
      "    equipment\n",
      "    errors\n",
      "    especially\n",
      "    essentially\n",
      "    esser\n",
      "    estimate\n",
      "    estimation\n",
      "    exactly\n",
      "    examinationa\n",
      "    examiners\n",
      "    exams\n",
      "    exceeds\n",
      "    except\n",
      "    exception\n",
      "    excludes\n",
      "    exempts\n",
      "    exodus\n",
      "    expect\n",
      "    expenses\n",
      "    exploiting\n",
      "    face\n",
      "    factor\n",
      "    factors\n",
      "    facts\n",
      "    failing\n",
      "    fails\n",
      "    failures\n",
      "    fairras\n",
      "    favor\n",
      "    fees\n",
      "    female\n",
      "    figures\n",
      "    finally\n",
      "    find\n",
      "    five\n",
      "    focuses\n",
      "    foreign\n",
      "    form\n",
      "    formally\n",
      "    formance\n",
      "    forms\n",
      "    full\n",
      "    funded\n",
      "    gain\n",
      "    gaining\n",
      "    gains\n",
      "    good\n",
      "    gordon\n",
      "    government\n",
      "    grading\n",
      "    gradual\n",
      "    gradually\n",
      "    grandfathers\n",
      "    guarantee\n",
      "    hand\n",
      "    harm\n",
      "    he\n",
      "    health\n",
      "    his\n",
      "    hold\n",
      "    holding\n",
      "    holt\n",
      "    how\n",
      "    hurdle\n",
      "    hypothesis\n",
      "    identical\n",
      "    identified\n",
      "    identifying\n",
      "    iii\n",
      "    im\n",
      "    imately\n",
      "    immediately\n",
      "    impacts\n",
      "    implication\n",
      "    imply\n",
      "    improve\n",
      "    improved\n",
      "    include\n",
      "    incom\n",
      "    incompetent\n",
      "    increased\n",
      "    incur\n",
      "    indeed\n",
      "    indepen\n",
      "    indicates\n",
      "    individual\n",
      "    induces\n",
      "    inefficient\n",
      "    inflict\n",
      "    influences\n",
      "    inframarginal\n",
      "    innate\n",
      "    interesting\n",
      "    interests\n",
      "    interviewed\n",
      "    introduction\n",
      "    invest\n",
      "    investments\n",
      "    ironically\n",
      "    irreparable\n",
      "    issues\n",
      "    iteration\n",
      "    iv\n",
      "    j1school\n",
      "    james\n",
      "    jobs\n",
      "    joseph\n",
      "    journeymen\n",
      "    judge\n",
      "    judged\n",
      "    june\n",
      "    just\n",
      "    kalachek\n",
      "    karen\n",
      "    keith\n",
      "    known\n",
      "    kruger\n",
      "    language\n",
      "    last\n",
      "    latters\n",
      "    lawrence\n",
      "    laws\n",
      "    least\n",
      "    lee\n",
      "    lesser\n",
      "    level\n",
      "    levels\n",
      "    li\n",
      "    like\n",
      "    limit\n",
      "    linear\n",
      "    loses\n",
      "    louis\n",
      "    low\n",
      "    mainly\n",
      "    management\n",
      "    manuscript\n",
      "    march\n",
      "    marginal\n",
      "    material\n",
      "    mathematics\n",
      "    maximum\n",
      "    mean\n",
      "    means\n",
      "    measured\n",
      "    measures\n",
      "    mellow\n",
      "    members\n",
      "    ment\n",
      "    merely\n",
      "    met\n",
      "    might\n",
      "    million\n",
      "    miss\n",
      "    motivated\n",
      "    multiple\n",
      "    murray\n",
      "    native\n",
      "    natural\n",
      "    naturalized\n",
      "    neither\n",
      "    neutralizing\n",
      "    newton\n",
      "    ninety\n",
      "    nonexistent\n",
      "    nonnative\n",
      "    nonnatives\n",
      "    nonpecuniary\n",
      "    notably\n",
      "    note\n",
      "    noted\n",
      "    observed\n",
      "    obtained\n",
      "    obtaining\n",
      "    office\n",
      "    ogy\n",
      "    oklahoma\n",
      "    opportunities\n",
      "    optician\n",
      "    ordinary\n",
      "    otherwise\n",
      "    outcome\n",
      "    overinvest\n",
      "    overstates\n",
      "    parallel\n",
      "    parameters\n",
      "    parentheses\n",
      "    part\n",
      "    partial\n",
      "    parts\n",
      "    passed\n",
      "    per\n",
      "    perfomance\n",
      "    perform\n",
      "    periods\n",
      "    permitting\n",
      "    persons\n",
      "    petent\n",
      "    physical\n",
      "    physicians\n",
      "    physics\n",
      "    physiol\n",
      "    plication\n",
      "    po\n",
      "    policies\n",
      "    poor\n",
      "    portant\n",
      "    portion\n",
      "    position\n",
      "    practice\n",
      "    practitioners\n",
      "    preceding\n",
      "    prelicensing\n",
      "    preparation\n",
      "    preparing\n",
      "    president\n",
      "    pretest\n",
      "    prevailing\n",
      "    preventing\n",
      "    previously\n",
      "    printing\n",
      "    prior\n",
      "    probabilities\n",
      "    procedure\n",
      "    proficiency\n",
      "    profit\n",
      "    proponents\n",
      "    provide\n",
      "    provided\n",
      "    provider\n",
      "    provision\n",
      "    proxy\n",
      "    pushing\n",
      "    qualities\n",
      "    quantities\n",
      "    range\n",
      "    raphson\n",
      "    rather\n",
      "    ratio\n",
      "    ratioa\n",
      "    rationale\n",
      "    reading\n",
      "    realize\n",
      "    really\n",
      "    reapplying\n",
      "    reasonable\n",
      "    recently\n",
      "    recommendation\n",
      "    references\n",
      "    regents\n",
      "    registration\n",
      "    regression\n",
      "    regulation\n",
      "    regulations\n",
      "    reject\n",
      "    relate\n",
      "    relating\n",
      "    relevancy\n",
      "    remarks\n",
      "    renner\n",
      "    replacing\n",
      "    reports\n",
      "    required\n",
      "    residual\n",
      "    respect\n",
      "    respectively\n",
      "    restrictive\n",
      "    restricts\n",
      "    resulted\n",
      "    retire\n",
      "    retirees\n",
      "    retirements\n",
      "    retiring\n",
      "    reveal\n",
      "    rinehart\n",
      "    rottenberg\n",
      "    routine\n",
      "    safety\n",
      "    said\n",
      "    satisfied\n",
      "    savvy\n",
      "    scale\n",
      "    schooling\n",
      "    science\n",
      "    section\n",
      "    sense\n",
      "    service\n",
      "    sharply\n",
      "    she\n",
      "    shown\n",
      "    shows\n",
      "    shrink\n",
      "    shrinks\n",
      "    side\n",
      "    signals\n",
      "    simon\n",
      "    simple\n",
      "    simultaneous\n",
      "    so\n",
      "    socially\n",
      "    solved\n",
      "    somewhat\n",
      "    sorting\n",
      "    spanish\n",
      "    speed\n",
      "    spent\n",
      "    squares\n",
      "    st\n",
      "    standard\n",
      "    statements\n",
      "    statistic\n",
      "    statistically\n",
      "    stronger\n",
      "    subject\n",
      "    subjects\n",
      "    subsequent\n",
      "    succeed\n",
      "    succeeded\n",
      "    successive\n",
      "    suffered\n",
      "    suggest\n",
      "    summarizes\n",
      "    supplied\n",
      "    suppose\n",
      "    surprising\n",
      "    survey\n",
      "    systematic\n",
      "    systemcommunications\n",
      "    take\n",
      "    taking\n",
      "    tasks\n",
      "    taste\n",
      "    tastes\n",
      "    teach\n",
      "    technique\n",
      "    ten\n",
      "    tendency\n",
      "    them\n",
      "    thewritten\n",
      "    third\n",
      "    thomas\n",
      "    though\n",
      "    three\n",
      "    tialism\n",
      "    tion\n",
      "    tions\n",
      "    tive\n",
      "    tongue\n",
      "    too\n",
      "    transitional\n",
      "    trap\n",
      "    treatment\n",
      "    true\n",
      "    try\n",
      "    tullock\n",
      "    turn\n",
      "    typical\n",
      "    typically\n",
      "    unable\n",
      "    unaware\n",
      "    unbiased\n",
      "    undertaken\n",
      "    unemployment\n",
      "    unim\n",
      "    united\n",
      "    universal\n",
      "    unless\n",
      "    unlicensed\n",
      "    unpublished\n",
      "    unreported\n",
      "    unsuccessful\n",
      "    use\n",
      "    using\n",
      "    value\n",
      "    values\n",
      "    various\n",
      "    vector\n",
      "    very\n",
      "    veteran\n",
      "    vi\n",
      "    via\n",
      "    vii\n",
      "    voluntarily\n",
      "    weidenbaum\n",
      "    wesley\n",
      "    western\n",
      "    what\n",
      "    while\n",
      "    why\n",
      "    winston\n",
      "    wisconsin\n",
      "    working\n",
      "    works\n",
      "    xv\n",
      "    zero\n"
     ]
    }
   ],
   "source": [
    "# Track the meaningful dictonaries\n",
    "freq_dict = {}\n",
    "\n",
    "# Read file line by line\n",
    "for line in journal_0:\n",
    "    assert isinstance(line, str)\n",
    "    pair = line.strip().split()\n",
    "    \n",
    "    # Separate word/freq\n",
    "    word, freq = pair\n",
    "    assert isinstance(word, str)\n",
    "    \n",
    "    # Filter by word's attribute\n",
    "    check_results = [check_func(word) for check_func in check_funcs]\n",
    "    if any(check_results):\n",
    "        continue\n",
    "    freq_dict.update({word: freq})\n",
    "\n",
    "journal_0.close()\n",
    "display(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'freq_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-60c9f6fe080a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreq_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'freq_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "# Data\n",
    "data = []\n",
    "for word in freq_dict:\n",
    "    freq = freq_dict[word]\n",
    "    data.append([word, freq])\n",
    "\n",
    "# Columns\n",
    "columns = [\"word\", \"freq\"]\n",
    "\n",
    "# Index\n",
    "index = list(range(len(data_word)))\n",
    "\n",
    "# DataFrame\n",
    "dataframe = pd.DataFrame(data, columns=columns, index=index)\n",
    "\n",
    "# Print Test\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word freq\n",
      "0    licensing   58\n",
      "1      written   40\n",
      "2  examination   32\n",
      "3         test   32\n",
      "4      workers   27\n",
      "     word freq\n",
      "0      pp   39\n",
      "1   paper   27\n",
      "2   cloth   17\n",
      "3   price   17\n",
      "4  listed   16\n",
      "      word freq\n",
      "0   search  112\n",
      "1      job   55\n",
      "2      ojs   51\n",
      "3     wage   43\n",
      "4  workers   35\n",
      "        word freq\n",
      "0      costs  103\n",
      "1  treatment   83\n",
      "2       were   82\n",
      "3   patients   78\n",
      "4    program   75\n",
      "      word freq\n",
      "0    james   15\n",
      "1     john   15\n",
      "2  richard   13\n",
      "3     alan   11\n",
      "4    david   10\n",
      "       word freq\n",
      "0    income  142\n",
      "1  families  135\n",
      "2   marital  119\n",
      "3     rates   89\n",
      "4    family   83\n",
      "           word freq\n",
      "0      earnings   63\n",
      "1   achievement   37\n",
      "2    motivation   35\n",
      "3    background   34\n",
      "4  intelligence   33\n",
      "       word freq\n",
      "0  teachers  160\n",
      "1    school   85\n",
      "2   teacher   72\n",
      "3   schools   53\n",
      "4  transfer   42\n",
      "       word freq\n",
      "0  earnings   41\n",
      "1   college   20\n",
      "2  security   18\n",
      "3    social   18\n",
      "4    school   16\n",
      "       word freq\n",
      "0        ui   64\n",
      "1    search   48\n",
      "2       job   28\n",
      "3  benefits   25\n",
      "4      data   15\n",
      "         word freq\n",
      "0        quit   86\n",
      "1         pay   71\n",
      "2  government   65\n",
      "3        size   64\n",
      "4        firm   54\n",
      "         word freq\n",
      "0   wisconsin   20\n",
      "1   economics   18\n",
      "2    research   13\n",
      "3  university    7\n",
      "4     poverty    6\n",
      "        word freq\n",
      "0         pp   48\n",
      "1      paper   29\n",
      "2      cloth   27\n",
      "3  institute   11\n",
      "4      price   11\n",
      "        word freq\n",
      "0     mental  148\n",
      "1     health  141\n",
      "2   coverage   80\n",
      "3  insurance   77\n",
      "4   services   76\n",
      "         word freq\n",
      "0   wisconsin   10\n",
      "1     journal    9\n",
      "2    research    9\n",
      "3       human    8\n",
      "4  university    7\n",
      "        word freq\n",
      "0    poverty  130\n",
      "1   earnings  114\n",
      "2  transfers   98\n",
      "3     growth   56\n",
      "4        aed   50\n",
      "        word freq\n",
      "0     mental   58\n",
      "1     health   48\n",
      "2       care   19\n",
      "3  treatment   17\n",
      "4        has   16\n",
      "           word freq\n",
      "0  unemployment   99\n",
      "1      training   71\n",
      "2        effect   48\n",
      "3         labor   45\n",
      "4       teenage   44\n",
      "         word freq\n",
      "0   wisconsin   20\n",
      "1   economics   16\n",
      "2    research   13\n",
      "3     poverty    7\n",
      "4  university    7\n",
      "       word freq\n",
      "0    social   46\n",
      "1  security   42\n",
      "2    system   17\n",
      "3   program   15\n",
      "4  derthick   12\n"
     ]
    }
   ],
   "source": [
    "# Run filtering for each file\n",
    "for file in filtered_list:\n",
    "    # Open file\n",
    "    try:\n",
    "        file_open = open(file, mode=\"r\")\n",
    "    except IOError:\n",
    "        print(\"Error opening file {0}\".format(file))\n",
    "        exit(0)\n",
    "    \n",
    "    # Create output file\n",
    "    output_name = \"Result_\" + file\n",
    "    output_file = open(output_name, mode=\"w+\")\n",
    "    \n",
    "    # Track for max length word\n",
    "    # Used for formatting output data\n",
    "    max_length = float(\"-inf\")\n",
    "        \n",
    "    # Initiate freq_dict -> {word: freq}\n",
    "    freq_dict = {}\n",
    "    \n",
    "    # Read by line\n",
    "    for line in file_open:\n",
    "        assert isinstance(line, str)\n",
    "        pair = line.strip().split()\n",
    "    \n",
    "        # Separate word/freq\n",
    "        word, freq = pair\n",
    "        assert isinstance(word, str)\n",
    "        \n",
    "        # Filter by word's attribute\n",
    "        check_results = [check_func(word) for check_func in check_funcs]\n",
    "        if any(check_results):\n",
    "            continue\n",
    "            \n",
    "        # Update max_length\n",
    "        if len(word) > max_length:\n",
    "            max_length = len(word)\n",
    "        freq_dict.update({word: freq})\n",
    "    \n",
    "    # Close reading file\n",
    "    file_open.close()\n",
    "    \n",
    "    # Create Dataframe\n",
    "    # Data\n",
    "    data = []\n",
    "    for word in freq_dict:\n",
    "        freq = freq_dict[word]\n",
    "        data.append([word, freq])\n",
    "    \n",
    "    # Columns\n",
    "    columns = [\"word\", \"freq\"]\n",
    "    \n",
    "    # Index\n",
    "    index = list(range(len(freq_dict)))\n",
    "    \n",
    "    # DataFrame\n",
    "    dataframe = pd.DataFrame(data, columns=columns, index=index)\n",
    "    \n",
    "    # Write to output file\n",
    "    for word in freq_dict:\n",
    "        freq = freq_dict[word]\n",
    "        output_file.write(word.ljust(max_length + 5))\n",
    "        output_file.write(freq + \"\\n\")\n",
    "    \n",
    "    output_file.close()\n",
    "    print(dataframe.head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
