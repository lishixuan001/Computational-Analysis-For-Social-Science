{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error Code:\n",
    "    0: Error opening file\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Clarify the mission N number for this .ipynb\n",
    "N_number = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a display function for visualization   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "def display(items):\n",
    "    print(namestr(items, globals()))\n",
    "    for item in items:\n",
    "        print(\"    \" + item)\n",
    "\n",
    "# Test display\n",
    "# test_dict = {\"A\": [1, 2, 3], \"B\": [4, 5, 6]}\n",
    "# display(test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths and related files (addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53528 files detected under current directory. \n"
     ]
    }
   ],
   "source": [
    "mypath = \"./\"\n",
    "zip_file_name = \"receipt-id-773931-part-001\"\n",
    "zip_file = zipfile.ZipFile(mypath + zip_file_name + \".zip\")\n",
    "file_name_list = zip_file.namelist()\n",
    "# Should return 4 folders if testing on ASG Zip\n",
    "print(\"{0} files detected under current directory. \".format(len(file_name_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter files by their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13382 files remained after filename filtering. \n"
     ]
    }
   ],
   "source": [
    "def filter_by_filename(files_list):\n",
    "    \"\"\"Function filtering files by filenames.\n",
    "    Only accepts files starts with \"journal-article\"\n",
    "    \"\"\"\n",
    "    filtered_list = []\n",
    "    mask_match = \"ngram\" + str(N_number) + \"/journal-article\"\n",
    "    for filename in files_list:\n",
    "        # Check if the filename starts with \"journal-article\"\n",
    "        assert isinstance(filename, str)\n",
    "        # Check the first 20 characters of the file name\n",
    "        if filename.startswith(mask_match, 0, len(mask_match)):\n",
    "            filtered_list.append(filename)\n",
    "    return filtered_list\n",
    "\n",
    "# Run \"filter_by_filename\" for current directory\n",
    "filtered_list = filter_by_filename(file_name_list)\n",
    "print(\"{0} files remained after filename filtering. \".format(len(filtered_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define methods filtering ngram characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions checking word attributes (single-letter, starts/ends with numebr)\n",
    "def is_single_letter(word):\n",
    "    assert isinstance(word, str)\n",
    "    return len(word) <= 1\n",
    "\n",
    "def starts_with_number(word):\n",
    "    assert isinstance(word, str)\n",
    "    try:\n",
    "        return word[0].isdigit()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def ends_with_number(word):\n",
    "    assert isinstance(word, str)\n",
    "    try:\n",
    "        return word[len(word) - 1].isdigit()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Summary of check functions\n",
    "check_funcs = [\n",
    "    is_single_letter, \n",
    "    starts_with_number, \n",
    "    ends_with_number,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define method parse ISSN from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define function getting article ID from a filename by parsing pattern\n",
    "Pattern: journal-article-10.2307_977118-ngram1.txt\n",
    "\"\"\"\n",
    "def parse_id(filename):\n",
    "    id_number_lst = re.findall(\"_(.+)-ngram1.txt\", filename)\n",
    "    if len(id_number_lst) == 1:\n",
    "        return id_number_lst[0]\n",
    "    print(\"Parse_ID Error: Filename does not match pattern. \")\n",
    "    return None\n",
    "\n",
    "# Test Parsing\n",
    "# print(filtered_list[0])\n",
    "# print(parse_id(filtered_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate through the files and clean data (Create DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0%\n",
      "Progress: 1%\n",
      "Progress: 2%\n",
      "Progress: 3%\n",
      "Progress: 4%\n",
      "Progress: 5%\n",
      "Progress: 6%\n",
      "Progress: 7%\n",
      "Progress: 8%\n",
      "Progress: 9%\n",
      "Progress: 10%\n",
      "Progress: 11%\n",
      "Progress: 12%\n",
      "Progress: 13%\n",
      "Progress: 14%\n",
      "Progress: 15%\n",
      "Progress: 16%\n",
      "Progress: 17%\n",
      "Progress: 18%\n",
      "Progress: 19%\n",
      "Progress: 20%\n",
      "Progress: 21%\n",
      "Progress: 22%\n",
      "Progress: 23%\n",
      "Progress: 24%\n",
      "Progress: 25%\n",
      "Progress: 26%\n",
      "Progress: 27%\n",
      "Progress: 28%\n",
      "Progress: 29%\n",
      "Progress: 30%\n",
      "Progress: 31%\n",
      "Progress: 32%\n",
      "Progress: 33%\n",
      "Progress: 34%\n",
      "Progress: 35%\n",
      "Progress: 36%\n",
      "Progress: 37%\n",
      "Progress: 38%\n",
      "Progress: 39%\n",
      "Progress: 40%\n",
      "Progress: 41%\n",
      "Progress: 42%\n",
      "Progress: 43%\n",
      "Progress: 44%\n",
      "Progress: 45%\n",
      "Progress: 46%\n",
      "Progress: 47%\n",
      "Progress: 48%\n",
      "Progress: 49%\n",
      "Progress: 50%\n",
      "Progress: 51%\n",
      "Progress: 52%\n",
      "Progress: 53%\n",
      "Progress: 54%\n",
      "Progress: 55%\n",
      "Progress: 56%\n",
      "Progress: 57%\n",
      "Progress: 58%\n",
      "Progress: 59%\n",
      "Progress: 60%\n",
      "Progress: 61%\n",
      "Progress: 62%\n",
      "Progress: 63%\n",
      "Progress: 64%\n",
      "Progress: 65%\n",
      "Progress: 66%\n",
      "Progress: 67%\n",
      "Progress: 68%\n",
      "Progress: 69%\n",
      "Progress: 70%\n",
      "Progress: 71%\n",
      "Progress: 72%\n",
      "Progress: 73%\n",
      "Progress: 74%\n",
      "Progress: 75%\n",
      "Progress: 76%\n",
      "Progress: 77%\n",
      "Progress: 78%\n",
      "Progress: 79%\n",
      "Progress: 80%\n",
      "Progress: 81%\n",
      "Progress: 82%\n",
      "Progress: 83%\n",
      "Progress: 84%\n",
      "Progress: 85%\n",
      "Progress: 86%\n",
      "Progress: 87%\n",
      "Progress: 88%\n",
      "Progress: 89%\n",
      "Progress: 90%\n",
      "Progress: 91%\n",
      "Progress: 92%\n",
      "Progress: 93%\n",
      "Progress: 94%\n",
      "Progress: 95%\n",
      "Progress: 96%\n",
      "Progress: 97%\n",
      "Progress: 98%\n",
      "Progress: 99%\n",
      "          word freq\n",
      "0  information  131\n",
      "1     planning  100\n",
      "2          can   48\n",
      "3      systems   43\n",
      "4      complex   41\n"
     ]
    }
   ],
   "source": [
    "# Run filtering for each file\n",
    "progress = list(range(0, len(filtered_list), len(filtered_list) // 99))\n",
    "\n",
    "\"\"\"\n",
    "Data\n",
    "\"\"\"\n",
    "data = []\n",
    "for file_num in range(0, len(filtered_list)):\n",
    "    \n",
    "    file = filtered_list[file_num]\n",
    "    # Open file\n",
    "    try:\n",
    "        file_open = zip_file.open(file, mode=\"r\")\n",
    "    except IOError:\n",
    "        print(\"Error opening file {0}\".format(file))\n",
    "        exit(0)\n",
    "    \n",
    "    # Read by line\n",
    "    for line in file_open:\n",
    "        # Line decode using UTF-8\n",
    "        line = line.decode(\"utf-8\")\n",
    "        assert isinstance(line, str)\n",
    "        pair = line.strip().split()\n",
    "    \n",
    "        # Separate word/freq\n",
    "        word, freq = pair\n",
    "        assert isinstance(word, str)\n",
    "        \n",
    "        # Filter by word's attribute\n",
    "        check_results = [check_func(word) for check_func in check_funcs]\n",
    "        if any(check_results):\n",
    "            continue\n",
    "            \n",
    "        # Update data for DataFrame\n",
    "        data.append([word, freq])\n",
    "    \n",
    "    # Close reading file\n",
    "    file_open.close()\n",
    "    \n",
    "    # Track Progress\n",
    "    if len(progress) > 0 and file_num >= progress[0]:\n",
    "        print(\"Progress: {}%\".format(100 - len(progress)))\n",
    "        progress.pop(0)\n",
    "    \n",
    "\"\"\"\n",
    "Columns\n",
    "\"\"\"\n",
    "columns = [\"word\", \"freq\"]\n",
    "\n",
    "\"\"\"\n",
    "Index\n",
    "\"\"\"\n",
    "index = list(range(len(data)))\n",
    "\n",
    "\"\"\"\n",
    "DataFrame\n",
    "\"\"\"\n",
    "dataframe = pd.DataFrame(data, columns=columns, index=index)\n",
    "\n",
    "    \n",
    "# Print Sample Output\n",
    "print(dataframe.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Data into SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Store data from DataFrame into SQLite\n",
    "ngram | issn | words | freq |\n",
    "\"\"\"\n",
    "\n",
    "# Define path towards the database\n",
    "db_name = \"ngram.db\"\n",
    "db_path = join(mypath, db_name)\n",
    "\n",
    "# Connect to the database\n",
    "database = sqlite3.connect(db_path)\n",
    "\n",
    "# Define a cursor to execute commands towards the database\n",
    "cursor = database.cursor()\n",
    "\n",
    "# Create table \"dataset\n",
    "cur.execute(\"CREATE TABLE dataset (n_number, issn, words, freq);\")\n",
    "\n",
    "# This is the qmark style:\n",
    "cur.execute(\"INSERT INTO dataset VALUES (?, ?)\", (who, age))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word freq\n",
      "0  information  131\n",
      "1     planning  100\n",
      "2          can   48\n",
      "3      systems   43\n",
      "4      complex   41\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
