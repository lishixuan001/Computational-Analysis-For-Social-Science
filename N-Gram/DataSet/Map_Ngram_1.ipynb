{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exit Code:\n",
    "    0: Error opening file\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define formatted display function\n",
    "Used to replace regular print function\n",
    "\"\"\"\n",
    "# Get name of an object\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "# Display with format\n",
    "def display(items, func=None):\n",
    "    print(namestr(items, globals()))\n",
    "    for item in items:\n",
    "        if func:\n",
    "            item = func(item)\n",
    "        print(\"     {0}\".format(item))\n",
    "\n",
    "# Test display\n",
    "# test_dict = {\"A\": [1, 2, 3], \"B\": [4, 5, 6]}\n",
    "# display(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define function to filter out directories Results_1, Results_2, Results_3\n",
    "@param Assume Input does NOT start with \"./\" or \"../\"\n",
    "\"\"\"\n",
    "def valid_direct(direct_name):\n",
    "    assert isinstance(direct_name, str)\n",
    "    \n",
    "    # Exculde if name starts with \".\"\n",
    "    if direct_name.startswith(\".\"):\n",
    "        return False\n",
    "    \n",
    "    # Test if name starts with ngram\n",
    "    if re.match(\"Results_\\d\", direct_name):\n",
    "        return True\n",
    "    \n",
    "    # Otherwise\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Results_1', 'Results_2', 'Results_3']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get filtering results\n",
    "\"\"\"\n",
    "datapath = \"./\"\n",
    "directories = sorted([direct for direct in os.listdir(datapath) if valid_direct(direct)])\n",
    "print(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function checking valid filenames.\n",
    "-- Only accepts files starts with \"journal-article\"\n",
    "\"\"\"\n",
    "def valid_filename(filename):\n",
    "    if re.match(\"^journal-article-.+-ngram1.txt$\", filename):\n",
    "        return True\n",
    "    return False\n",
    "# print(valid_filename(\"journal-article-10.2307_43488821-ngram1.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define function getting article ID from a filename by parsing pattern\n",
    "Pattern: journal-article-10.2307_977118-ngram1.txt\n",
    "\"\"\"\n",
    "def parse_id(filename):\n",
    "    id_number_lst = re.findall(\"_(.+)-ngram1.txt\", filename)\n",
    "    if len(id_number_lst) == 1:\n",
    "        return id_number_lst[0]\n",
    "    print(\"Parse_ID Error: Filename does not match pattern. \")\n",
    "    return None\n",
    "# print(parse_id(\"journal-article-10.2307_977503-ngram1.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All Columns features for N-Gram [1-3]\n",
    "\"\"\"\n",
    "ngram_columns = [\n",
    "    [\"word_ngram_1\", \"freq_ngram_1\"],\n",
    "    [\"word1_ngram_2\", \"word2_ngram_2\", \"freq_ngram_2\"],\n",
    "    [\"word1_ngram_3\", \"word2_ngram_3\", \"word3_ngram_3\", \"freq_ngram_3\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Merge Results for cleaned N-Gram data\n",
    "1. Collect results from Results_1 directory and gather all information into a DataFrame\n",
    "2. Assume all files in the Results_N directory is valid in content\n",
    "3. Filenames will be checked\n",
    "@param n_number: N for Results_N; n_number can be int -> [1, 2, 3]\n",
    "\"\"\"\n",
    "def collect_data(n_number):\n",
    "    \n",
    "    assert type(n_number) == int\n",
    "\n",
    "    # directpath = \"./Results_1/\" .etc\n",
    "    direct_folder = join(datapath + \"Results_\" + str(n_number) + \"/\")\n",
    "    \n",
    "    \"\"\"\n",
    "    DATA\n",
    "    \"\"\"\n",
    "    # Initiate freq_list -> {{(words0): freq0}, {(words1), freq1}}\n",
    "    freq_dict = {}\n",
    "    \n",
    "    # Print Number of Files Found in Directory\n",
    "    num_of_files = len(listdir(direct_folder))\n",
    "    print(\"{0} files found in directory '{1}'\".format(num_of_files, direct_folder))\n",
    "    \n",
    "    # Keep track of the progress\n",
    "    count = 0\n",
    "    progress = list(range(0, num_of_files, num_of_files // 99))\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Iterate through the files in the directory\n",
    "    for filename in listdir(direct_folder):\n",
    "        \n",
    "        direct_file = join(direct_folder, filename)\n",
    "        \n",
    "        # Validate if is file and if valid filename\n",
    "        if isfile(direct_file) and valid_filename(filename):\n",
    "            # Open file\n",
    "            try:\n",
    "                file_open = open(direct_file, mode=\"r\", encoding=\"utf-8\")\n",
    "            except Exception as e:\n",
    "                print(\"Error opening file {0}\".format(filename))\n",
    "                print(\"Error message: <{0}>\".format(e))\n",
    "                exit(0)\n",
    "\n",
    "            # Read by line\n",
    "            # line -> \"word1 word2 word3 5\"\n",
    "            for line in file_open:\n",
    "                \n",
    "                assert isinstance(line, str)\n",
    "                \n",
    "                # pair -> \"[\"word1\", \"word2\", \"word3\", \"5\"]\n",
    "                pair = line.strip().split()\n",
    "                assert len(pair) >= 2\n",
    "\n",
    "                # Separate word/freq\n",
    "                # Words in tuple form since it will be the key in file_dict\n",
    "                # freq will be a int digit as value in file_dict \n",
    "                words, freq = pair[:-1], pair[-1]\n",
    "\n",
    "                # Initiate dataline\n",
    "                dataline = []\n",
    "                \n",
    "                # Save into dataline\n",
    "                for word in words:\n",
    "                    dataline.append(word)\n",
    "                dataline.append(freq)\n",
    "                \n",
    "                # Save dataline into data\n",
    "                data.append(dataline)\n",
    "\n",
    "            # Close reading file\n",
    "            file_open.close()\n",
    "\n",
    "            # Track Progress\n",
    "            count += 1\n",
    "            if len(progress) > 0 and count >= progress[0]:\n",
    "                print(\"Progress: {}%\".format(100 - len(progress)))\n",
    "                progress.pop(0)\n",
    "\n",
    "    \"\"\"\n",
    "    Columns\n",
    "    \"\"\"\n",
    "    # \"-1\" for matching correct index\n",
    "    columns = ngram_columns[n_number - 1] \n",
    "\n",
    "    \"\"\"\n",
    "    Index\n",
    "    \"\"\"\n",
    "    index = list(range(len(data)))\n",
    "\n",
    "    \"\"\"\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    dataframe = pd.DataFrame(data, columns=columns, index=index)\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13382 files found in directory './Results_1/'\n",
      "Progress: 0%\n",
      "Progress: 1%\n",
      "Progress: 2%\n",
      "Progress: 3%\n",
      "Progress: 4%\n",
      "Progress: 5%\n",
      "Progress: 6%\n",
      "Progress: 7%\n",
      "Progress: 8%\n",
      "Progress: 9%\n",
      "Progress: 10%\n",
      "Progress: 11%\n",
      "Progress: 12%\n",
      "Progress: 13%\n",
      "Progress: 14%\n",
      "Progress: 15%\n",
      "Progress: 16%\n",
      "Progress: 17%\n",
      "Progress: 18%\n",
      "Progress: 19%\n",
      "Progress: 20%\n",
      "Progress: 21%\n",
      "Progress: 22%\n",
      "Progress: 23%\n",
      "Progress: 24%\n",
      "Progress: 25%\n",
      "Progress: 26%\n",
      "Progress: 27%\n",
      "Progress: 28%\n",
      "Progress: 29%\n",
      "Progress: 30%\n",
      "Progress: 31%\n",
      "Progress: 32%\n",
      "Progress: 33%\n",
      "Progress: 34%\n",
      "Progress: 35%\n",
      "Progress: 36%\n",
      "Progress: 37%\n",
      "Progress: 38%\n",
      "Progress: 39%\n",
      "Progress: 40%\n",
      "Progress: 41%\n",
      "Progress: 42%\n",
      "Progress: 43%\n",
      "Progress: 44%\n",
      "Progress: 45%\n",
      "Progress: 46%\n",
      "Progress: 47%\n",
      "Progress: 48%\n",
      "Progress: 49%\n",
      "Progress: 50%\n",
      "Progress: 51%\n",
      "Progress: 52%\n",
      "Progress: 53%\n",
      "Progress: 54%\n",
      "Progress: 55%\n",
      "Progress: 56%\n",
      "Progress: 57%\n",
      "Progress: 58%\n",
      "Progress: 59%\n",
      "Progress: 60%\n",
      "Progress: 61%\n",
      "Progress: 62%\n",
      "Progress: 63%\n",
      "Progress: 64%\n",
      "Progress: 65%\n",
      "Progress: 66%\n",
      "Progress: 67%\n",
      "Progress: 68%\n",
      "Progress: 69%\n",
      "Progress: 70%\n",
      "Progress: 71%\n",
      "Progress: 72%\n",
      "Progress: 73%\n",
      "Progress: 74%\n",
      "Progress: 75%\n",
      "Progress: 76%\n",
      "Progress: 77%\n",
      "Progress: 78%\n",
      "Progress: 79%\n",
      "Progress: 80%\n",
      "Progress: 81%\n",
      "Progress: 82%\n",
      "Progress: 83%\n",
      "Progress: 84%\n",
      "Progress: 85%\n",
      "Progress: 86%\n",
      "Progress: 87%\n",
      "Progress: 88%\n",
      "Progress: 89%\n",
      "Progress: 90%\n",
      "Progress: 91%\n",
      "Progress: 92%\n",
      "Progress: 93%\n",
      "Progress: 94%\n",
      "Progress: 95%\n",
      "Progress: 96%\n",
      "Progress: 97%\n",
      "Progress: 98%\n",
      "Progress: 99%\n",
      "    word_ngram_1 freq_ngram_1\n",
      "0          found            1\n",
      "1  presentations            1\n",
      "2      disparity            2\n",
      "3   astronautics            1\n",
      "4          influ            1\n",
      "44457486\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "DataFrame Creation for N-Gram [1] \n",
    "\"\"\"\n",
    "dataframe = collect_data(1)\n",
    "\n",
    "print(dataframe.head())\n",
    "print(dataframe.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a Test File (NGram 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159935\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "mypath = \"./\"\n",
    "zip_file_name = \"test_files\"\n",
    "zip_file = zipfile.ZipFile(mypath + zip_file_name + \".zip\")\n",
    "file_name_list = zip_file.namelist()\n",
    "print(len(file_name_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter filenames for Test Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36267 files remained after filename filtering. \n"
     ]
    }
   ],
   "source": [
    "N_number = 1\n",
    "def filter_by_filename(files_list):\n",
    "    \"\"\"Function filtering files by filenames.\n",
    "    Only accepts files starts with \"journal-article\"\n",
    "    \"\"\"\n",
    "    filtered_list = []\n",
    "    mask_match = \"ngram\" + str(N_number) + \"/journal-article\"\n",
    "    for filename in files_list:\n",
    "        # Check if the filename starts with \"journal-article\"\n",
    "        assert isinstance(filename, str)\n",
    "        # Check the first 20 characters of the file name\n",
    "        if filename.startswith(mask_match, 0, len(mask_match)):\n",
    "            filtered_list.append(filename)\n",
    "    return filtered_list\n",
    "\n",
    "# Run \"filter_by_filename\" for current directory\n",
    "filtered_list = filter_by_filename(file_name_list)\n",
    "print(\"{0} files remained after filename filtering. \".format(len(filtered_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check word validity for Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions checking word attributes (single-letter, starts/ends with numebr)\n",
    "def is_single_letter(word):\n",
    "    assert isinstance(word, str)\n",
    "    return len(word) <= 1\n",
    "\n",
    "def starts_with_number(word):\n",
    "    assert isinstance(word, str)\n",
    "    try:\n",
    "        return word[0].isdigit()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def ends_with_number(word):\n",
    "    assert isinstance(word, str)\n",
    "    try:\n",
    "        return word[len(word) - 1].isdigit()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Summary of check functions\n",
    "check_funcs = [\n",
    "    is_single_letter, \n",
    "    starts_with_number, \n",
    "    ends_with_number,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame for Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a test file \n",
    "test_file_name = filtered_list[0]\n",
    "\n",
    "\"\"\"\n",
    "Data\n",
    "\"\"\"\n",
    "# Open file\n",
    "try:\n",
    "    file_open = zip_file.open(test_file_name, mode=\"r\")\n",
    "except IOError:\n",
    "    print(\"Error opening file {0}\".format(file))\n",
    "    exit(0)\n",
    "\n",
    "data_test = []    \n",
    "\n",
    "# Read by line\n",
    "for line in file_open:\n",
    "    # Line decode using UTF-8\n",
    "    line = line.decode(\"utf-8\")\n",
    "    assert isinstance(line, str)\n",
    "    pair = line.strip().split()\n",
    "\n",
    "    # Separate word/freq\n",
    "    word, freq = pair\n",
    "    assert isinstance(word, str)\n",
    "\n",
    "    # Filter by word's attribute\n",
    "    check_results = [check_func(word) for check_func in check_funcs]\n",
    "    if any(check_results):\n",
    "        continue\n",
    "\n",
    "    # Update data for DataFrame\n",
    "    data_test.append([word, freq])\n",
    "    \n",
    "\"\"\"\n",
    "Columns\n",
    "\"\"\"\n",
    "columns = [\"word\", \"freq\"]\n",
    "\n",
    "\"\"\"\n",
    "Index\n",
    "\"\"\"\n",
    "index = list(range(len(data_test)))\n",
    "\n",
    "\"\"\"\n",
    "DataFrame\n",
    "\"\"\"\n",
    "dataframe_test = pd.DataFrame(data_test, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_test: we\n",
      "==== Match! ====\n",
      "Time: 14.061488628387451\n",
      "Progress: 0%\n",
      "\n",
      "word_test: history\n",
      "==== Match! ====\n",
      "Time: 14.3613121509552\n",
      "\n",
      "word_test: oral\n",
      "==== Match! ====\n",
      "Time: 14.325449466705322\n",
      "\n",
      "word_test: all\n",
      "==== Match! ====\n",
      "Time: 14.232678651809692\n",
      "\n",
      "word_test: advice\n",
      "==== Match! ====\n",
      "Time: 14.303768396377563\n",
      "Progress: 1%\n",
      "\n",
      "word_test: evidence\n",
      "==== Match! ====\n",
      "Time: 14.406672477722168\n",
      "\n",
      "word_test: experiences\n",
      "==== Match! ====\n",
      "Time: 13.9123854637146\n",
      "\n",
      "word_test: first\n",
      "==== Match! ====\n",
      "Time: 14.054575681686401\n",
      "\n",
      "word_test: have\n",
      "==== Match! ====\n",
      "Time: 14.344773292541504\n",
      "Progress: 2%\n",
      "\n",
      "word_test: its\n",
      "==== Match! ====\n",
      "Time: 14.399255990982056\n",
      "\n",
      "word_test: should\n",
      "==== Match! ====\n",
      "Time: 14.125980615615845\n",
      "\n",
      "word_test: were\n",
      "==== Match! ====\n",
      "Time: 14.06918215751648\n",
      "\n",
      "word_test: also\n",
      "==== Match! ====\n",
      "Time: 14.55257534980774\n",
      "\n",
      "word_test: assessment\n",
      "==== Match! ====\n",
      "Time: 14.230801582336426\n",
      "Progress: 3%\n",
      "\n",
      "word_test: book\n",
      "==== Match! ====\n",
      "Time: 13.951858043670654\n",
      "\n",
      "word_test: both\n",
      "==== Match! ====\n",
      "Time: 14.28754472732544\n",
      "\n",
      "word_test: can\n",
      "==== Match! ====\n",
      "Time: 14.382683515548706\n",
      "\n",
      "word_test: collecting\n",
      "==== Match! ====\n",
      "Time: 14.1098792552948\n",
      "Progress: 4%\n",
      "\n",
      "word_test: didn\n",
      "==== Match! ====\n",
      "Time: 14.089111089706421\n",
      "\n",
      "word_test: directly\n",
      "==== Match! ====\n",
      "Time: 14.349435329437256\n",
      "\n",
      "word_test: don\n",
      "==== Match! ====\n",
      "Time: 14.27830696105957\n",
      "\n",
      "word_test: either\n",
      "==== Match! ====\n",
      "Time: 14.355125904083252\n",
      "\n",
      "word_test: england\n",
      "==== Match! ====\n",
      "Time: 14.329338788986206\n",
      "Progress: 5%\n",
      "\n",
      "word_test: great\n",
      "==== Match! ====\n",
      "Time: 14.40994930267334\n",
      "\n",
      "word_test: had\n",
      "==== Match! ====\n",
      "Time: 14.219425439834595\n",
      "\n",
      "word_test: know\n",
      "==== Match! ====\n",
      "Time: 13.955662727355957\n",
      "\n",
      "word_test: material\n",
      "==== Match! ====\n",
      "Time: 14.283160924911499\n",
      "Progress: 6%\n",
      "\n",
      "word_test: more\n",
      "==== Match! ====\n",
      "Time: 14.400851726531982\n",
      "\n",
      "word_test: new\n",
      "==== Match! ====\n",
      "Time: 14.213837623596191\n",
      "\n",
      "word_test: our\n",
      "==== Match! ====\n",
      "Time: 14.161310911178589\n",
      "\n",
      "word_test: past\n",
      "==== Match! ====\n",
      "Time: 14.458106994628906\n",
      "\n",
      "word_test: people\n",
      "==== Match! ====\n",
      "Time: 14.31107211112976\n",
      "Progress: 7%\n",
      "\n",
      "word_test: red\n",
      "==== Match! ====\n",
      "Time: 14.184775114059448\n",
      "\n",
      "word_test: relevant\n",
      "==== Match! ====\n",
      "Time: 14.272298097610474\n",
      "\n",
      "word_test: section\n",
      "==== Match! ====\n",
      "Time: 14.397608280181885\n",
      "\n",
      "word_test: teachers\n",
      "==== Match! ====\n",
      "Time: 14.155239343643188\n",
      "Progress: 8%\n",
      "\n",
      "word_test: themes\n",
      "==== Match! ====\n",
      "Time: 14.121091365814209\n",
      "\n",
      "word_test: understand\n",
      "==== Match! ====\n",
      "Time: 14.12496042251587\n",
      "\n",
      "word_test: which\n",
      "==== Match! ====\n",
      "Time: 14.203942775726318\n",
      "\n",
      "word_test: who\n",
      "==== Match! ====\n",
      "Time: 14.074828863143921\n",
      "Progress: 9%\n",
      "\n",
      "word_test: world\n",
      "==== Match! ====\n",
      "Time: 14.038267374038696\n",
      "\n",
      "word_test: about\n",
      "==== Match! ====\n",
      "Time: 14.435035228729248\n",
      "\n",
      "word_test: aftermath\n",
      "==== Match! ====\n",
      "Time: 14.137934923171997\n",
      "\n",
      "word_test: although\n",
      "==== Match! ====\n",
      "Time: 13.979803085327148\n",
      "\n",
      "word_test: another\n",
      "==== Match! ====\n",
      "Time: 14.322665214538574\n",
      "Progress: 10%\n",
      "\n",
      "word_test: any\n",
      "==== Match! ====\n",
      "Time: 14.474167108535767\n",
      "\n",
      "word_test: archer\n",
      "==== Match! ====\n",
      "Time: 14.247901916503906\n",
      "\n",
      "word_test: australia\n",
      "==== Match! ====\n",
      "Time: 13.899482727050781\n",
      "\n",
      "word_test: authors\n",
      "==== Match! ====\n",
      "Time: 14.445580005645752\n",
      "Progress: 11%\n",
      "\n",
      "word_test: because\n",
      "==== Match! ====\n",
      "Time: 14.264683485031128\n",
      "\n",
      "word_test: being\n",
      "==== Match! ====\n",
      "Time: 14.020285367965698\n",
      "\n",
      "word_test: bloody\n",
      "==== Match! ====\n",
      "Time: 14.120344161987305\n",
      "\n",
      "word_test: britain\n",
      "==== Match! ====\n",
      "Time: 14.331072807312012\n",
      "\n",
      "word_test: british\n",
      "==== Match! ====\n",
      "Time: 14.202569007873535\n",
      "Progress: 12%\n",
      "\n",
      "word_test: century\n",
      "==== Match! ====\n",
      "Time: 14.027701616287231\n",
      "\n",
      "word_test: class\n",
      "==== Match! ====\n",
      "Time: 14.290335893630981\n",
      "\n",
      "word_test: classroom\n",
      "==== Match! ====\n",
      "Time: 14.173328161239624\n",
      "\n",
      "word_test: clearly\n",
      "==== Match! ====\n",
      "Time: 14.22476840019226\n",
      "Progress: 13%\n",
      "\n",
      "word_test: confidence\n",
      "==== Match! ====\n",
      "Time: 13.819762945175171\n",
      "\n",
      "word_test: contingency\n",
      "==== Match! ====\n",
      "Time: 14.041574716567993\n",
      "\n",
      "word_test: contrasted\n",
      "==== Match! ====\n",
      "Time: 14.037976026535034\n",
      "\n",
      "word_test: convicts\n",
      "==== Match! ====\n",
      "Time: 14.032669067382812\n",
      "\n",
      "word_test: courses\n",
      "==== Match! ====\n",
      "Time: 14.35013747215271\n",
      "Progress: 14%\n",
      "\n",
      "word_test: criterion\n",
      "==== Match! ====\n",
      "Time: 14.335303544998169\n",
      "\n",
      "word_test: current\n",
      "==== Match! ====\n",
      "Time: 14.25787353515625\n",
      "\n",
      "word_test: curriculum\n",
      "==== Match! ====\n",
      "Time: 13.925373077392578\n",
      "\n",
      "word_test: deal\n",
      "==== Match! ====\n",
      "Time: 14.370318412780762\n",
      "Progress: 15%\n",
      "\n",
      "word_test: debate\n",
      "==== Match! ====\n",
      "Time: 14.3839852809906\n",
      "\n",
      "word_test: decolonialism\n",
      "==== Not Match ====\n",
      "Time: 13.877422332763672\n",
      "\n",
      "word_test: depression\n",
      "==== Match! ====\n",
      "Time: 13.92610764503479\n",
      "\n",
      "word_test: design\n",
      "==== Match! ====\n",
      "Time: 14.386772155761719\n",
      "\n",
      "word_test: despite\n",
      "==== Match! ====\n",
      "Time: 14.272651433944702\n",
      "Progress: 16%\n",
      "\n",
      "word_test: developed\n",
      "==== Match! ====\n",
      "Time: 13.85948896408081\n",
      "\n",
      "word_test: did\n",
      "==== Match! ====\n",
      "Time: 14.198445796966553\n",
      "\n",
      "word_test: difference\n",
      "==== Match! ====\n",
      "Time: 14.097289085388184\n",
      "\n",
      "word_test: direct\n",
      "==== Match! ====\n",
      "Time: 14.315766096115112\n",
      "Progress: 17%\n",
      "\n",
      "word_test: doing\n",
      "==== Match! ====\n",
      "Time: 14.00461220741272\n",
      "\n",
      "word_test: drake\n",
      "==== Match! ====\n",
      "Time: 14.365273475646973\n",
      "\n",
      "word_test: each\n",
      "==== Match! ====\n",
      "Time: 14.613556623458862\n",
      "\n",
      "word_test: empire\n",
      "==== Match! ====\n",
      "Time: 14.30353593826294\n",
      "Progress: 18%\n",
      "\n",
      "word_test: enable\n",
      "==== Match! ====\n",
      "Time: 14.296411514282227\n",
      "\n",
      "word_test: events\n",
      "==== Match! ====\n",
      "Time: 14.572560548782349\n",
      "\n",
      "word_test: examinations\n",
      "==== Match! ====\n",
      "Time: 13.93165397644043\n",
      "\n",
      "word_test: exploited\n",
      "==== Match! ====\n",
      "Time: 14.048306465148926\n",
      "\n",
      "word_test: fails\n",
      "==== Match! ====\n",
      "Time: 14.154650211334229\n",
      "Progress: 19%\n",
      "\n",
      "word_test: family\n",
      "==== Match! ====\n",
      "Time: 14.325820684432983\n",
      "\n",
      "word_test: far\n",
      "==== Match! ====\n",
      "Time: 14.129430294036865\n",
      "\n",
      "word_test: final\n",
      "==== Match! ====\n",
      "Time: 13.971028804779053\n",
      "\n",
      "word_test: focus\n",
      "==== Match! ====\n",
      "Time: 14.23361587524414\n",
      "Progress: 20%\n",
      "\n",
      "word_test: following\n",
      "==== Match! ====\n",
      "Time: 14.32839298248291\n",
      "\n",
      "word_test: from\n",
      "==== Match! ====\n",
      "Time: 14.088617086410522\n",
      "\n",
      "word_test: gcse\n",
      "==== Match! ====\n",
      "Time: 14.020551919937134\n",
      "\n",
      "word_test: general\n",
      "==== Match! ====\n",
      "Time: 14.410258531570435\n",
      "\n",
      "word_test: generation\n",
      "==== Match! ====\n",
      "Time: 14.159291982650757\n",
      "Progress: 21%\n",
      "\n",
      "word_test: getting\n",
      "==== Match! ====\n",
      "Time: 14.089531660079956\n",
      "\n",
      "word_test: going\n",
      "==== Match! ====\n",
      "Time: 14.218506097793579\n",
      "\n",
      "word_test: good\n",
      "==== Match! ====\n",
      "Time: 14.38308048248291\n",
      "\n",
      "word_test: has\n",
      "==== Match! ====\n",
      "Time: 14.268590927124023\n",
      "Progress: 22%\n",
      "\n",
      "word_test: hasn\n",
      "==== Match! ====\n",
      "Time: 13.98065972328186\n",
      "\n",
      "word_test: help\n",
      "==== Match! ====\n",
      "Time: 14.299238204956055\n",
      "\n",
      "word_test: helped\n",
      "==== Match! ====\n",
      "Time: 14.317454814910889\n",
      "\n",
      "word_test: here\n",
      "==== Match! ====\n",
      "Time: 14.253764629364014\n",
      "\n",
      "word_test: heroes\n",
      "==== Match! ====\n",
      "Time: 14.05794072151184\n",
      "Progress: 23%\n",
      "\n",
      "word_test: hesitant\n",
      "==== Match! ====\n",
      "Time: 14.309457302093506\n",
      "\n",
      "word_test: hidden\n",
      "==== Match! ====\n",
      "Time: 14.283409595489502\n",
      "\n",
      "word_test: home\n",
      "==== Match! ====\n",
      "Time: 14.074403285980225\n",
      "\n",
      "word_test: how\n",
      "==== Match! ====\n",
      "Time: 14.095867156982422\n",
      "Progress: 24%\n",
      "\n",
      "word_test: however\n",
      "==== Match! ====\n",
      "Time: 14.358075618743896\n",
      "\n",
      "word_test: ignored\n",
      "==== Match! ====\n",
      "Time: 14.375853776931763\n",
      "\n",
      "word_test: imperialism\n",
      "==== Match! ====\n",
      "Time: 13.763819694519043\n",
      "\n",
      "word_test: include\n",
      "==== Match! ====\n",
      "Time: 14.352721452713013\n",
      "\n",
      "word_test: india\n",
      "==== Match! ====\n",
      "Time: 14.559409618377686\n",
      "Progress: 25%\n",
      "\n",
      "word_test: indians\n",
      "==== Match! ====\n",
      "Time: 14.33198356628418\n",
      "\n",
      "word_test: individual\n",
      "==== Match! ====\n",
      "Time: 13.826984405517578\n",
      "\n",
      "word_test: initiate\n",
      "==== Match! ====\n",
      "Time: 14.44810700416565\n",
      "\n",
      "word_test: integration\n",
      "==== Match! ====\n",
      "Time: 14.030781507492065\n",
      "Progress: 26%\n",
      "\n",
      "word_test: interviewed\n",
      "==== Match! ====\n",
      "Time: 13.945499897003174\n",
      "\n",
      "word_test: investigated\n",
      "==== Match! ====\n",
      "Time: 13.838626623153687\n",
      "\n",
      "word_test: knew\n",
      "==== Match! ====\n",
      "Time: 14.251400709152222\n",
      "\n",
      "word_test: largely\n",
      "==== Match! ====\n",
      "Time: 14.265306949615479\n",
      "Progress: 27%\n",
      "\n",
      "word_test: learnt\n",
      "==== Match! ====\n",
      "Time: 14.143491744995117\n",
      "\n",
      "word_test: left\n",
      "==== Match! ====\n",
      "Time: 14.307854652404785\n",
      "\n",
      "word_test: leisure\n",
      "==== Match! ====\n",
      "Time: 14.36035704612732\n",
      "\n",
      "word_test: lessons\n",
      "==== Match! ====\n",
      "Time: 14.186279296875\n",
      "\n",
      "word_test: life\n",
      "==== Match! ====\n",
      "Time: 14.061460733413696\n",
      "Progress: 28%\n",
      "\n",
      "word_test: locality\n",
      "==== Match! ====\n",
      "Time: 14.274871110916138\n",
      "\n",
      "word_test: looked\n",
      "==== Match! ====\n",
      "Time: 14.335180282592773\n",
      "\n",
      "word_test: looking\n",
      "==== Match! ====\n",
      "Time: 14.09270191192627\n",
      "\n",
      "word_test: majority\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Match! ====\n",
      "Time: 14.058716773986816\n",
      "Progress: 29%\n",
      "\n",
      "word_test: make\n",
      "==== Match! ====\n",
      "Time: 14.367667198181152\n",
      "\n",
      "word_test: man\n",
      "==== Match! ====\n",
      "Time: 14.180984020233154\n",
      "\n",
      "word_test: map\n",
      "==== Match! ====\n",
      "Time: 13.97757363319397\n",
      "\n",
      "word_test: memories\n",
      "==== Match! ====\n",
      "Time: 14.109720706939697\n",
      "\n",
      "word_test: men\n",
      "==== Match! ====\n",
      "Time: 14.34794807434082\n",
      "Progress: 30%\n",
      "\n",
      "word_test: message\n",
      "==== Match! ====\n",
      "Time: 14.15237307548523\n",
      "\n",
      "word_test: most\n",
      "==== Match! ====\n",
      "Time: 14.025007724761963\n",
      "\n",
      "word_test: nation\n",
      "==== Match! ====\n",
      "Time: 14.474676609039307\n",
      "\n",
      "word_test: national\n",
      "==== Match! ====\n",
      "Time: 14.246641159057617\n",
      "Progress: 31%\n",
      "\n",
      "word_test: newsworthy\n",
      "==== Match! ====\n",
      "Time: 13.873561382293701\n",
      "\n",
      "word_test: nigel\n",
      "==== Match! ====\n",
      "Time: 14.318544626235962\n",
      "\n",
      "word_test: north\n",
      "==== Match! ====\n",
      "Time: 14.478025674819946\n",
      "\n",
      "word_test: nothing\n",
      "==== Match! ====\n",
      "Time: 14.378855228424072\n",
      "\n",
      "word_test: organised\n",
      "==== Match! ====\n",
      "Time: 13.87440013885498\n",
      "Progress: 32%\n",
      "\n",
      "word_test: other\n",
      "==== Match! ====\n",
      "Time: 14.412873029708862\n",
      "\n",
      "word_test: out\n",
      "==== Match! ====\n",
      "Time: 14.378080606460571\n",
      "\n",
      "word_test: over\n",
      "==== Match! ====\n",
      "Time: 14.180465698242188\n",
      "\n",
      "word_test: own\n",
      "==== Match! ====\n",
      "Time: 14.145538330078125\n",
      "Progress: 33%\n",
      "\n",
      "word_test: particular\n",
      "==== Match! ====\n",
      "Time: 14.095437288284302\n",
      "\n",
      "word_test: passage\n",
      "==== Match! ====\n",
      "Time: 14.135965347290039\n",
      "Progress: 35%\n",
      "\n",
      "word_test: purkis\n",
      "==== Match! ====\n",
      "Time: 14.156418800354004\n",
      "\n",
      "word_test: question\n",
      "==== Match! ====\n",
      "Time: 13.963181972503662\n",
      "\n",
      "word_test: questions\n",
      "==== Match! ====\n",
      "Time: 14.155563354492188\n",
      "\n",
      "word_test: referenced\n",
      "==== Match! ====\n",
      "Time: 14.034903049468994\n",
      "Progress: 36%\n",
      "\n",
      "word_test: related\n",
      "==== Match! ====\n",
      "Time: 14.204636096954346\n",
      "\n",
      "word_test: relating\n",
      "==== Match! ====\n",
      "Time: 14.172443628311157\n",
      "\n",
      "word_test: requirements\n",
      "==== Match! ====\n",
      "Time: 14.058183193206787\n",
      "\n",
      "word_test: researched\n",
      "==== Match! ====\n",
      "Time: 14.01637077331543\n",
      "\n",
      "word_test: respondent\n",
      "==== Match! ====\n",
      "Time: 13.804454803466797\n",
      "Progress: 37%\n",
      "\n",
      "word_test: right\n",
      "==== Match! ====\n",
      "Time: 14.342894077301025\n",
      "\n",
      "word_test: ruled\n",
      "==== Match! ====\n",
      "Time: 14.440139532089233\n",
      "\n",
      "word_test: sallie\n",
      "==== Match! ====\n",
      "Time: 14.262444257736206\n",
      "\n",
      "word_test: sample\n",
      "==== Match! ====\n",
      "Time: 14.126966714859009\n",
      "Progress: 38%\n",
      "\n",
      "word_test: school\n",
      "==== Match! ====\n",
      "Time: 14.43550419807434\n",
      "\n",
      "word_test: schoolboy\n",
      "==== Match! ====\n",
      "Time: 14.128176927566528\n",
      "\n",
      "word_test: schooling\n",
      "==== Match! ====\n",
      "Time: 13.92270541191101\n",
      "\n",
      "word_test: schools\n",
      "==== Match! ====\n",
      "Time: 14.255343914031982\n",
      "\n",
      "word_test: selected\n",
      "==== Match! ====\n",
      "Time: 14.296962976455688\n",
      "Progress: 39%\n",
      "\n",
      "word_test: sentence\n",
      "==== Match! ====\n",
      "Time: 14.156657934188843\n",
      "\n",
      "word_test: shared\n",
      "==== Match! ====\n",
      "Time: 14.128256797790527\n",
      "\n",
      "word_test: shepley\n",
      "==== Not Match ====\n",
      "Time: 14.322874784469604\n",
      "\n",
      "word_test: shown\n",
      "==== Match! ====\n",
      "Time: 14.482689142227173\n",
      "Progress: 40%\n",
      "\n",
      "word_test: simply\n",
      "==== Match! ====\n",
      "Time: 14.275146722793579\n",
      "\n",
      "word_test: since\n",
      "==== Match! ====\n",
      "Time: 14.197021722793579\n",
      "\n",
      "word_test: slightly\n",
      "==== Match! ====\n",
      "Time: 14.33295750617981\n",
      "\n",
      "word_test: so\n",
      "==== Match! ====\n",
      "Time: 14.303215026855469\n",
      "\n",
      "word_test: sort\n",
      "==== Match! ====\n",
      "Time: 14.144705057144165\n",
      "Progress: 41%\n",
      "\n",
      "word_test: sound\n",
      "==== Match! ====\n",
      "Time: 14.224985122680664\n",
      "\n",
      "word_test: sources\n",
      "==== Match! ====\n",
      "Time: 14.5019052028656\n",
      "\n",
      "word_test: stanley\n",
      "==== Match! ====\n",
      "Time: 14.256785869598389\n",
      "\n",
      "word_test: strike\n",
      "==== Match! ====\n",
      "Time: 14.153414726257324\n",
      "Progress: 42%\n",
      "\n",
      "word_test: stuart\n",
      "==== Match! ====\n",
      "Time: 14.36384916305542\n",
      "\n",
      "word_test: suggestions\n",
      "==== Match! ====\n",
      "Time: 14.097115516662598\n",
      "\n",
      "word_test: sure\n",
      "==== Match! ====\n",
      "Time: 14.185416460037231\n",
      "\n",
      "word_test: tackle\n",
      "==== Match! ====\n",
      "Time: 14.240149021148682\n",
      "\n",
      "word_test: tasks\n",
      "==== Match! ====\n",
      "Time: 14.469873905181885\n",
      "Progress: 43%\n",
      "\n",
      "word_test: taught\n",
      "==== Match! ====\n",
      "Time: 14.46509337425232\n",
      "\n",
      "word_test: themselves\n",
      "==== Match! ====\n",
      "Time: 13.78113865852356\n",
      "\n",
      "word_test: thing\n",
      "==== Match! ====\n",
      "Time: 14.36685061454773\n",
      "\n",
      "word_test: think\n",
      "==== Match! ====\n",
      "Time: 14.471765518188477\n",
      "Progress: 44%\n",
      "\n",
      "word_test: thornes\n",
      "==== Not Match ====\n",
      "Time: 14.28916883468628\n",
      "\n",
      "word_test: thoroughly\n",
      "==== Match! ====\n",
      "Time: 13.834451913833618\n",
      "\n",
      "word_test: those\n",
      "==== Match! ====\n",
      "Time: 14.470316410064697\n",
      "\n",
      "word_test: thought\n",
      "==== Match! ====\n",
      "Time: 14.321047067642212\n",
      "Progress: 45%\n",
      "\n",
      "word_test: through\n",
      "==== Match! ====\n",
      "Time: 14.166815519332886\n",
      "\n",
      "word_test: trouble\n",
      "==== Match! ====\n",
      "Time: 14.145042181015015\n",
      "\n",
      "word_test: twentieth\n",
      "==== Match! ====\n",
      "Time: 14.25104308128357\n",
      "\n",
      "word_test: up\n",
      "==== Match! ====\n",
      "Time: 14.21804666519165\n",
      "\n",
      "word_test: use\n",
      "==== Match! ====\n",
      "Time: 14.058412313461304\n",
      "Progress: 46%\n",
      "\n",
      "word_test: used\n",
      "==== Match! ====\n",
      "Time: 14.197144746780396\n",
      "\n",
      "word_test: ve\n",
      "==== Match! ====\n",
      "Time: 14.422791481018066\n",
      "\n",
      "word_test: view\n",
      "==== Match! ====\n",
      "Time: 14.09816598892212\n",
      "\n",
      "word_test: war\n",
      "==== Match! ====\n",
      "Time: 13.939799785614014\n",
      "Progress: 47%\n",
      "\n",
      "word_test: way\n",
      "==== Match! ====\n",
      "Time: 14.232165336608887\n",
      "\n",
      "word_test: welcome\n",
      "==== Match! ====\n",
      "Time: 14.243321180343628\n",
      "\n",
      "word_test: well\n",
      "==== Match! ====\n",
      "Time: 14.10035753250122\n",
      "\n",
      "word_test: what\n",
      "==== Match! ====\n",
      "Time: 14.04959774017334\n",
      "\n",
      "word_test: when\n",
      "==== Match! ====\n",
      "Time: 14.296575784683228\n",
      "Progress: 48%\n",
      "\n",
      "word_test: whole\n",
      "==== Match! ====\n",
      "Time: 14.228245258331299\n",
      "\n",
      "word_test: witnessing\n",
      "==== Match! ====\n",
      "Time: 13.837838649749756\n",
      "\n",
      "word_test: women\n",
      "==== Match! ====\n",
      "Time: 14.241079330444336\n",
      "\n",
      "word_test: work\n",
      "==== Match! ====\n",
      "Time: 14.353745698928833\n",
      "Progress: 49%\n",
      "\n",
      "word_test: working\n",
      "==== Match! ====\n",
      "Time: 14.231996536254883\n",
      "\n",
      "word_test: younger\n",
      "==== Match! ====\n",
      "Time: 13.954822063446045\n",
      "0.49318181818181817\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "match_count = 0\n",
    "\n",
    "# Keep track of the progress\n",
    "count = 0\n",
    "progress = np.linspace(0, dataframe_test.size, num=100).tolist()\n",
    "\n",
    "# Iterate through the test's dataframe\n",
    "for index, row in dataframe_test.iterrows():\n",
    "    \n",
    "    word_test, freq_test = row[\"word\"], row[\"freq\"]\n",
    "    \n",
    "    print(\"\\nword_test: {}\".format(word_test))\n",
    "    \n",
    "    # Check if the word exist in the training set\n",
    "    # Count time for reference\n",
    "    start = time.time()\n",
    "    if dataframe[\"word_ngram_1\"].str.contains(word_test).any():\n",
    "        match_count += 1\n",
    "        print(\"==== Match! ====\")\n",
    "    else:\n",
    "        print(\"==== Not Match ====\")\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Time: {}\".format(end - start))\n",
    "    \n",
    "    # Track Progress\n",
    "    count += 1\n",
    "    if len(progress) > 0 and count >= progress[0]:\n",
    "        print(\"Progress: {}%\".format(100 - len(progress)))\n",
    "        progress.pop(0)\n",
    "\n",
    "match_rate = match_count / dataframe_test.shape[0]\n",
    "\n",
    "print(match_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
